#!/usr/bin/env python3
"""
GPU Timeline Integration Layer
Integrates GPU rendering with existing timeline system and provides fallback modes.
"""

import time
import logging
from typing import List, Dict, Optional, Any
from enum import Enum

from .gpu_timeline_renderer import GPUTimelineRenderer, RenderingMode
from .texture_cache import TimelineTextureCache, CacheLayer

class RenderBackend(Enum):
    AUTO = "auto"           # Automatically choose best available
    GPU_INSTANCED = "gpu"   # GPU instanced rendering
    CPU_IMGUI = "cpu"       # Traditional ImGui CPU rendering
    HYBRID = "hybrid"       # Mix of GPU and CPU rendering

class GPUTimelineIntegration:
    """
    Integration layer between existing timeline code and GPU rendering system.
    
    Provides:
    - Automatic fallback to CPU rendering if GPU unavailable
    - Performance monitoring and adaptive backend selection
    - Seamless integration with existing timeline interface
    - Hot-swappable rendering backends
    """
    
    def __init__(self, 
                 app_instance: Any,
                 preferred_backend: RenderBackend = RenderBackend.AUTO,
                 logger: Optional[logging.Logger] = None):
        
        self.app = app_instance
        self.logger = logger or logging.getLogger(__name__)
        self.preferred_backend = preferred_backend
        
        # Rendering backends
        self.gpu_renderer: Optional[GPUTimelineRenderer] = None
        self.texture_cache: Optional[TimelineTextureCache] = None
        self.current_backend = RenderBackend.CPU_IMGUI
        
        # Performance tracking
        self.render_times = {
            RenderBackend.GPU_INSTANCED: [],
            RenderBackend.CPU_IMGUI: [],
            RenderBackend.HYBRID: []
        }
        
        # Configuration
        self.gpu_threshold_points = 1000  # Switch to GPU above this point count
        self.performance_window_frames = 100  # Frames to average for performance decisions
        self.auto_fallback_enabled = True
        
        # State tracking
        self.last_render_time = 0
        self.consecutive_gpu_failures = 0
        self.max_gpu_failures = 3
        
        # Performance stats storage
        self.render_stats = {
            'gpu': {'avg_ms': 0, 'min_ms': 0, 'max_ms': 0, 'frames_tracked': 0, 'last_ms': 0},
            'cpu': {'avg_ms': 0, 'min_ms': 0, 'max_ms': 0, 'frames_tracked': 0, 'last_ms': 0},
            'hybrid': {'avg_ms': 0, 'min_ms': 0, 'max_ms': 0, 'frames_tracked': 0, 'last_ms': 0},
            'gpu_details': {
                'points_rendered': 0, 'lines_rendered': 0, 'render_time_ms': 0.0,
                'gpu_upload_time_ms': 0.0, 'draw_calls': 0
            },
            'texture_cache': {
                'hits': 0, 'misses': 0, 'evictions': 0, 'memory_used_mb': 0,
                'render_time_saved_ms': 0, 'hit_rate_percent': 0, 'cached_textures': 0
            },
            'current_backend': 'cpu',
            'gpu_failures': 0
        }
        
        # Initialize backends
        self._initialize_backends()
    
    def _initialize_backends(self):
        """Initialize available rendering backends"""
        
        # Always try to initialize GPU backend
        try:
            self.gpu_renderer = GPUTimelineRenderer(self.logger)
            if self.gpu_renderer.initialize_gpu_resources():
                self.logger.info("GPU timeline renderer initialized successfully")
                
                # Initialize texture cache
                self.texture_cache = TimelineTextureCache(
                    max_cache_size_mb=256,
                    logger=self.logger
                )
                
                if self.texture_cache.initialize():
                    self.logger.info("Texture cache initialized successfully")
                
                # Set initial backend based on preference
                if self.preferred_backend in [RenderBackend.AUTO, RenderBackend.GPU_INSTANCED]:
                    self.current_backend = RenderBackend.GPU_INSTANCED
                
            else:
                self.logger.warning("GPU initialization failed, falling back to CPU rendering")
                
        except Exception as e:
            self.logger.error(f"Failed to initialize GPU backend: {e}")
    
    def render_timeline_optimized(self,
                                actions_list: List[Dict],
                                canvas_abs_pos: tuple,
                                canvas_size: tuple,
                                app_state: Any,
                                draw_list: Any,
                                mouse_pos: tuple,
                                selected_indices: List[int] = None,
                                hovered_index: int = -1) -> bool:
        """
        Main timeline rendering function with intelligent backend selection.
        
        This replaces the existing timeline rendering logic in interactive_timeline.py
        
        Returns True if rendering succeeded, False if fallback needed.
        """
        
        start_time = time.perf_counter()
        
        # Determine optimal rendering strategy
        backend = self._select_optimal_backend(actions_list, app_state)
        
        # Execute rendering based on selected backend
        success = False
        
        if backend == RenderBackend.GPU_INSTANCED:
            success = self._render_with_gpu(
                actions_list, canvas_abs_pos, canvas_size, app_state, draw_list,
                mouse_pos, selected_indices or [], hovered_index
            )
            
            if not success:
                self.consecutive_gpu_failures += 1
                self.logger.warning(f"GPU rendering failed (attempt {self.consecutive_gpu_failures})")
                
                # Automatic fallback if too many failures
                if (self.consecutive_gpu_failures >= self.max_gpu_failures and 
                    self.auto_fallback_enabled):
                    self.logger.info("Falling back to CPU rendering due to repeated GPU failures")
                    self.current_backend = RenderBackend.CPU_IMGUI
                    success = self._render_with_cpu(actions_list, canvas_abs_pos, canvas_size, 
                                                  app_state, draw_list, mouse_pos, selected_indices, hovered_index)
        
        elif backend == RenderBackend.HYBRID:
            success = self._render_with_hybrid(
                actions_list, canvas_abs_pos, canvas_size, app_state, draw_list,
                mouse_pos, selected_indices or [], hovered_index
            )
        
        else:  # CPU_IMGUI
            success = self._render_with_cpu(
                actions_list, canvas_abs_pos, canvas_size, app_state, draw_list,
                mouse_pos, selected_indices or [], hovered_index
            )
        
        # Track performance
        render_time = (time.perf_counter() - start_time) * 1000
        self._track_performance(backend, render_time)
        
        # Reset failure counter on success
        if success and backend == RenderBackend.GPU_INSTANCED:
            self.consecutive_gpu_failures = 0
        
        return success
    
    def _select_optimal_backend(self, actions_list: List[Dict], app_state: Any) -> RenderBackend:
        """Intelligently select the best rendering backend for current conditions"""

        point_count = len(actions_list) if actions_list else 0

        # If GPU is not available or has failed too many times
        if (not self.gpu_renderer or
            not self.gpu_renderer.gl_initialized or
            self.consecutive_gpu_failures >= self.max_gpu_failures):
            selected_backend = RenderBackend.CPU_IMGUI
            self.logger.debug(
                f"Backend: CPU_IMGUI (GPU unavailable or too many failures: {self.consecutive_gpu_failures})"
            )
            return selected_backend

        # Force backend if explicitly set
        if self.preferred_backend != RenderBackend.AUTO:
            self.logger.debug(
                f"Backend: {self.preferred_backend.value} (explicitly set, points: {point_count})"
            )
            return self.preferred_backend

        # Auto-selection logic
        if point_count < self.gpu_threshold_points:
            # Small datasets: CPU is probably fine and simpler
            selected_backend = RenderBackend.CPU_IMGUI
            reason = f"point_count ({point_count}) < threshold ({self.gpu_threshold_points})"
        elif point_count < 50000:
            # Medium datasets: GPU gives good benefits
            selected_backend = RenderBackend.GPU_INSTANCED
            reason = f"medium dataset (points: {point_count})"
        else:
            # Large datasets: GPU is essential for performance
            selected_backend = RenderBackend.GPU_INSTANCED
            reason = f"large dataset (points: {point_count})"

        # Log backend selection with reasoning
        self.logger.debug(
            f"Backend: {selected_backend.value} - {reason}"
        )

        return selected_backend
    
    def _render_with_gpu(self,
                        actions_list: List[Dict],
                        canvas_abs_pos: tuple,
                        canvas_size: tuple,
                        app_state: Any,
                        draw_list: Any,
                        mouse_pos: tuple,
                        selected_indices: List[int],
                        hovered_index: int) -> bool:
        """GPU-Accelerated rendering that works with ImGui"""
        
        # For now, use "GPU-accelerated CPU" approach:
        # - Use GPU-style optimizations (vectorized operations, smart culling)
        # - But draw through ImGui draw list for compatibility
        # This gives most GPU benefits without ImGui integration issues
        
        try:
            import numpy as np
            import imgui
            
            if not actions_list:
                return True
            
            # draw_list is passed as parameter
            
            # GPU-style vectorized preprocessing
            start_time = time.perf_counter()
            
            # Convert to numpy arrays for vectorized operations (GPU-like processing)
            ats = np.array([action["at"] for action in actions_list], dtype=np.float64)
            poss = np.array([action["pos"] for action in actions_list], dtype=np.int32)
            
            # Vectorized coordinate transformations (GPU-equivalent)
            zoom_factor_ms_per_px = getattr(app_state, 'timeline_zoom_factor_ms_per_px', 1.0)
            pan_offset_ms = getattr(app_state, 'timeline_pan_offset_ms', 0)
            
            # Transform coordinates (vectorized like GPU)
            x_coords = canvas_abs_pos[0] + (ats - pan_offset_ms) / zoom_factor_ms_per_px
            y_coords = canvas_abs_pos[1] + canvas_size[1] - (poss / 100.0 * canvas_size[1])
            
            # GPU-style culling - only process visible points
            visible_mask = (x_coords >= canvas_abs_pos[0] - 50) & (x_coords <= canvas_abs_pos[0] + canvas_size[0] + 50)
            visible_indices = np.where(visible_mask)[0]
            
            if len(visible_indices) == 0:
                return True
            
            # GPU-style LOD (Level of Detail) - NOW UNIFIED WITH CPU
            avg_interval = np.mean(np.diff(ats)) if len(ats) > 1 else 50
            points_per_pixel = zoom_factor_ms_per_px / avg_interval if avg_interval > 0 else 1.0

            # CRITICAL FIX: Unified LOD logic matching CPU behavior
            # Always show ALL points for small datasets (< 1000)
            if len(actions_list) < 1000:
                # Small datasets: render ALL visible points (matches CPU behavior)
                render_indices = visible_indices
            elif points_per_pixel > 8.0:
                # Ultra-dense: waveform mode - drastically reduce points
                step = max(1, int(points_per_pixel / 2.0))
                render_indices = visible_indices[::step]
            elif points_per_pixel > 2.0:
                # Dense: skip some points
                step = max(1, int(points_per_pixel / 1.5))
                render_indices = visible_indices[::step]
            else:
                # Normal density: render all visible
                render_indices = visible_indices
            
            # GPU-style batch processing for lines - SAME COLORS AS CPU
            if len(render_indices) > 1:
                # Vectorized speed calculations (like GPU shader)
                line_indices = render_indices[:-1]
                next_indices = render_indices[1:]
                
                dt = ats[next_indices] - ats[line_indices]
                dpos = np.abs(poss[next_indices] - poss[line_indices])
                speeds = np.divide(dpos, dt / 1000.0, out=np.zeros_like(dpos, dtype=np.float64), where=dt > 1e-5)
                
                # Use SAME color calculation as CPU rendering
                # Access through app that was passed to the integration
                colors_rgba = self.app.utility.get_speed_colors_vectorized(speeds)
                # Use same alpha/thickness logic as CPU (simplified for now)
                alpha = 1.0  # TODO: Could pass is_previewing from timeline if needed
                thickness = 2.0
                
                # Batch draw lines (ImGui compatible) - SAME as CPU
                for i in range(len(line_indices)):
                    idx1, idx2 = line_indices[i], next_indices[i]
                    x1, y1 = x_coords[idx1], y_coords[idx1]
                    x2, y2 = x_coords[idx2], y_coords[idx2]
                    
                    # Use exact same color calculation as CPU
                    color = colors_rgba[i]
                    final_color = imgui.get_color_u32_rgba(color[0], color[1], color[2], color[3] * alpha)
                    draw_list.add_line(x1, y1, x2, y2, final_color, thickness)
            
            # GPU-style batch processing for points - SAME COLORS AS CPU
            # CRITICAL FIX: Only render INTERACTIVE points (hovered/selected/dragged)
            if points_per_pixel < 4.0:  # Only draw points when not too dense
                point_radius = getattr(app_state, 'timeline_point_radius', 4)
                
                # Import TimelineColors to match CPU rendering exactly
                from config.element_group_colors import TimelineColors
                
                for idx in render_indices:
                    # Check if point is being dragged (not implemented in this simple version)
                    is_being_dragged = False  # Could implement if needed
                    
                    # Check if point is selected
                    is_primary_selected = (idx == hovered_index)
                    is_in_multi_selection = (idx in selected_indices)
                    
                    # Check if point is hovered (simplified version)
                    is_hovered_pt = (idx == hovered_index)
                    
                    # PERFORMANCE: ONLY render interactive points (hovered/selected/dragged)
                    # This matches CPU rendering behavior exactly
                    is_interactive = (is_primary_selected or is_in_multi_selection or is_being_dragged or is_hovered_pt)
                    
                    # Skip rendering ALL non-interactive points
                    if not is_interactive:
                        continue  # Skip rendering this point
                    
                    x, y = x_coords[idx], y_coords[idx]
                    
                    # Use EXACT same point coloring logic as CPU rendering
                    point_radius_draw = point_radius
                    pt_color_tuple = TimelineColors.POINT_DEFAULT
                    
                    # Apply SAME color logic as CPU rendering
                    if is_being_dragged:
                        pt_color_tuple = TimelineColors.POINT_DRAGGING
                        point_radius_draw += 1
                    elif is_primary_selected or is_in_multi_selection:
                        pt_color_tuple = TimelineColors.POINT_SELECTED
                        if is_in_multi_selection and not is_primary_selected:
                            point_radius_draw += 0.5
                    elif is_hovered_pt:
                        pt_color_tuple = TimelineColors.POINT_HOVER
                    
                    # Convert color tuple to ImGui color (same as CPU)
                    point_alpha = 1.0  # TODO: Could pass is_previewing from timeline if needed
                    final_pt_color = imgui.get_color_u32_rgba(pt_color_tuple[0], pt_color_tuple[1], pt_color_tuple[2], pt_color_tuple[3] * point_alpha)
                    
                    draw_list.add_circle_filled(x, y, point_radius_draw, final_pt_color)
                    
                    # Add selection border (same as CPU)
                    if is_primary_selected and not is_being_dragged:
                        draw_list.add_circle(x, y, point_radius_draw + 1, imgui.get_color_u32_rgba(*TimelineColors.SELECTED_POINT_BORDER), thickness=1.0)
            
            # Update performance stats
            render_time = (time.perf_counter() - start_time) * 1000
            self.render_stats['gpu_details']['render_time_ms'] = render_time
            # Count only interactive points that were actually rendered
            interactive_count = len([idx for idx in render_indices 
                                    if idx == hovered_index or idx in selected_indices])
            self.render_stats['gpu_details']['points_rendered'] = interactive_count
            self.render_stats['gpu_details']['lines_rendered'] = max(0, len(render_indices) - 1)
            
            return True
            
        except Exception as e:
            self.logger.error(f"GPU-accelerated rendering failed: {e}")
            return False
    
    def _render_with_cpu(self,
                        actions_list: List[Dict],
                        canvas_abs_pos: tuple,
                        canvas_size: tuple,
                        app_state: Any,
                        draw_list: Any,
                        mouse_pos: tuple,
                        selected_indices: List[int],
                        hovered_index: int) -> bool:
        """
        Delegate to timeline's native CPU rendering.

        CRITICAL FIX: Return False to force timeline to use its proven CPU fallback path.
        For datasets < gpu_threshold_points, this ensures the timeline's optimized
        CPU rendering (with proper LOD for < 1000 points) handles the drawing.
        """

        try:
            # Log that we're deferring to timeline's CPU rendering
            self.logger.debug(
                f"Deferring {len(actions_list)} points to timeline's native CPU rendering "
                f"(point count < GPU threshold: {self.gpu_threshold_points})"
            )

            # Return False to signal timeline should use its CPU fallback path
            # This leverages the existing, well-tested CPU rendering with proper:
            # - LOD logic (shows ALL points for < 1000)
            # - Vectorized color calculations
            # - Cached array operations
            # - Conditional point rendering
            return False

        except Exception as e:
            self.logger.error(f"CPU rendering delegation failed: {e}")
            return False
    
    def _render_with_hybrid(self,
                          actions_list: List[Dict],
                          canvas_abs_pos: tuple,
                          canvas_size: tuple,
                          app_state: Any,
                          draw_list: Any,
                          mouse_pos: tuple,
                          selected_indices: List[int],
                          hovered_index: int) -> bool:
        """Hybrid rendering: GPU for bulk data, CPU for interactions"""
        
        try:
            # Render bulk data (lines, background points) with GPU
            bulk_success = self._render_with_gpu(
                actions_list, canvas_abs_pos, canvas_size, app_state,
                [], -1  # No selection/hover for bulk rendering
            )
            
            if not bulk_success:
                return False
            
            # Render interactive elements (selection, hover) with CPU for precision
            if selected_indices or hovered_index >= 0:
                # Render only selected/hovered points with CPU for precise interaction
                interactive_actions = []
                
                for idx in selected_indices:
                    if 0 <= idx < len(actions_list):
                        interactive_actions.append(actions_list[idx])
                
                if 0 <= hovered_index < len(actions_list):
                    if actions_list[hovered_index] not in interactive_actions:
                        interactive_actions.append(actions_list[hovered_index])
                
                # CPU render interactive elements on top
                if interactive_actions:
                    return self._render_with_cpu(
                        interactive_actions, canvas_abs_pos, canvas_size,
                        app_state, draw_list, mouse_pos, selected_indices, hovered_index
                    )
            
            return True
        
        except Exception as e:
            self.logger.error(f"Hybrid rendering failed: {e}")
            return False
    
    def _track_performance(self, backend: RenderBackend, render_time_ms: float):
        """Track rendering performance for adaptive backend selection"""
        
        times_list = self.render_times[backend]
        times_list.append(render_time_ms)
        
        # Keep only recent frames
        if len(times_list) > self.performance_window_frames:
            times_list.pop(0)
        
        self.last_render_time = render_time_ms
    
    def get_performance_summary(self) -> Dict:
        """Get performance summary for all backends"""
        
        # Return the render_stats dictionary that contains everything we need
        self.render_stats['current_backend'] = self.current_backend.value if hasattr(self.current_backend, 'value') else str(self.current_backend)
        self.render_stats['gpu_failures'] = self.consecutive_gpu_failures
        
        return self.render_stats
    
    def set_rendering_backend(self, backend: RenderBackend):
        """Manually set the rendering backend"""
        self.preferred_backend = backend
        self.current_backend = backend
        self.consecutive_gpu_failures = 0  # Reset failure counter
    
    def cleanup(self):
        """Clean up all rendering resources"""
        if self.gpu_renderer:
            self.gpu_renderer.cleanup()
        
        if self.texture_cache:
            self.texture_cache.cleanup()
        
        self.logger.info("GPU timeline integration cleaned up")

# Helper function to integrate with existing timeline code
def integrate_gpu_rendering_with_timeline(timeline_instance, app_instance):
    """
    Helper function to integrate GPU rendering with existing InteractiveFunscriptTimeline.
    
    This would be called during timeline initialization to add GPU capabilities.
    """
    
    # Add GPU integration as a member of the timeline instance
    timeline_instance.gpu_integration = GPUTimelineIntegration(
        app_instance=app_instance,
        logger=app_instance.logger if hasattr(app_instance, 'logger') else None
    )
    
    # Store original render method for fallback
    timeline_instance._original_render_method = getattr(timeline_instance, 'render_timeline_content', None)
    
    # Replace render method with GPU-accelerated version
    def gpu_accelerated_render(self, *args, **kwargs):
        # Try GPU rendering first
        if self.gpu_integration.render_timeline_optimized(*args, **kwargs):
            return True
        
        # Fallback to original method if GPU fails
        if self._original_render_method:
            return self._original_render_method(*args, **kwargs)
        
        return False
    
    # Bind the new method
    timeline_instance.render_timeline_content = gpu_accelerated_render.__get__(timeline_instance)
    
    return timeline_instance