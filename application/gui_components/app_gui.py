import glfw
import OpenGL.GL as gl
import imgui
from imgui.integrations.glfw import GlfwRenderer
import numpy as np
import cv2
import time
import threading
import queue
import os
from typing import List, Dict
from collections import deque

from config import constants, element_group_colors
from application.classes import GaugeWindow, ImGuiFileDialog, InteractiveFunscriptTimeline, LRDialWindow, MainMenu, Simulator3DWindow
from application.gui_components import ControlPanelUI, VideoDisplayUI, VideoNavigationUI, ChapterListWindow, InfoGraphsUI, GeneratedFileManagerWindow, AutotunerWindow, KeyboardShortcutsDialog, ToolbarUI, ChapterTypeManagerUI
from application.utils import _format_time, ProcessingThreadManager, TaskType, TaskPriority


class GUI:
    def __init__(self, app_logic):
        self.app = app = app_logic
        self.window = None
        self.impl = None
        self.window_width = app.app_settings.get("window_width", 1800)
        self.window_height = app.app_settings.get("window_height", 1000)
        self.main_menu_bar_height = 0

        self.constants = constants
        self.colors = element_group_colors.AppGUIColors

        self.frame_texture_id = 0
        self.heatmap_texture_id = 0
        self.funscript_preview_texture_id = 0
        self.enhanced_preview_texture_id = 0  # Dedicated texture for enhanced preview tooltips

        # --- Advanced Threading Architecture ---
        # Decoupled, non-blocking preview/heatmap pipeline with larger queues and background workers
        max_queue = 8
        self.preview_task_queue = queue.Queue(maxsize=max_queue)
        self.preview_results_queue = queue.Queue(maxsize=max_queue)
        self.shutdown_event = threading.Event()
        # Start 2 workers to avoid stalls under load
        self.preview_worker_threads = [
            threading.Thread(target=self._preview_generation_worker, daemon=True, name="PreviewWorker-1"),
            threading.Thread(target=self._preview_generation_worker, daemon=True, name="PreviewWorker-2")
        ]
        for t in self.preview_worker_threads: t.start()
        
        # New ProcessingThreadManager for GPU-intensive operations
        self.processing_thread_manager = ProcessingThreadManager(
            max_worker_threads=2,
            logger=app.logger
        )
        
        # Progress tracking for threaded operations
        self.active_threaded_operations: Dict[str, Dict] = {}
        self.processing_thread_manager.set_global_progress_callback(self._handle_threaded_progress)

        # --- State for incremental texture generation ---
        self.last_submitted_action_count_timeline: int = 0
        self.last_submitted_action_count_heatmap: int = 0

        # Performance monitoring
        self.component_render_times = {}
        self.perf_log_interval = 10  # Log performance every 10 seconds
        self.last_perf_log_time = time.time()
        self.perf_frame_count = 0
        self.perf_accumulated_times = {}
        
        # Frontend data queue - maintains continuous data flow
        self._frontend_perf_queue = deque(maxlen=2)  # Keep last 2 data points
        self._frontend_perf_queue.append({
            'accumulated_times': {},
            'frame_count': 0,
            'timestamp': time.time()
        })
        
        # Extended monitoring capabilities
        self.video_decode_times = deque(maxlen=100)  # Track video decoding
        self.gpu_memory_usage = 0
        self.last_gpu_check = 0
        self.disk_io_times = deque(maxlen=50)  # Track file operations
        self.network_operation_times = deque(maxlen=30)  # Track network calls

        # Standard Components (owned by GUI)
        self.file_dialog = ImGuiFileDialog(app_logic_instance=app)
        self.main_menu = MainMenu(app, gui_instance=self)
        self.toolbar_ui = ToolbarUI(app)
        self.gauge_window_ui_t1 = GaugeWindow(app, timeline_num=1)
        self.gauge_window_ui_t2 = GaugeWindow(app, timeline_num=2)
        self.movement_bar_ui = LRDialWindow(app)  # Movement Bar (backward compatible name)
        self.simulator_3d_window_ui = Simulator3DWindow(app)

        self.timeline_editor1 = InteractiveFunscriptTimeline(app_instance=app, timeline_num=1)
        self.timeline_editor2 = InteractiveFunscriptTimeline(app_instance=app, timeline_num=2)

        # Modularized UI Panel Components
        self.control_panel_ui = ControlPanelUI(app)
        self.video_display_ui = VideoDisplayUI(app, self)  # Pass self for texture updates
        self.video_navigation_ui = VideoNavigationUI(app, self)  # Pass self for texture methods
        self.info_graphs_ui = InfoGraphsUI(app)
        self.chapter_list_window_ui = ChapterListWindow(app, nav_ui=self.video_navigation_ui)
        self.chapter_type_manager_ui = ChapterTypeManagerUI(app)
        self.generated_file_manager_ui = GeneratedFileManagerWindow(app)
        self.autotuner_window_ui = AutotunerWindow(app)
        self.keyboard_shortcuts_dialog = KeyboardShortcutsDialog(app)

        # UI state for the dialog's radio buttons
        self.selected_batch_method_idx_ui = 0
        self.batch_overwrite_mode_ui = 0  # 0: Process All, 1: Skip Existing
        self.batch_apply_post_processing_ui = True
        self.batch_copy_funscript_to_video_location_ui = True
        self.batch_generate_roll_file_ui = True
        self.batch_apply_ultimate_autotune_ui = True

        self.control_panel_ui.timeline_editor1 = self.timeline_editor1
        self.control_panel_ui.timeline_editor2 = self.timeline_editor2

        self.last_preview_update_time_timeline = 0.0
        self.last_preview_update_time_heatmap = 0.0
        self.preview_update_interval_seconds = constants.UI_PREVIEW_UPDATE_INTERVAL_S

        self.last_mouse_pos_for_energy_saver = (0, 0)
        self.app.energy_saver.reset_activity_timer()
        
        # Simple arrow key navigation state
        current_time = time.time()
        self.arrow_key_state = {
            'last_seek_time': current_time,
            'seek_interval': 0.033,  # Will be updated based on video FPS
            'initial_press_time': current_time,
            'continuous_delay': 0.2,  # 200ms delay before continuous playback (allows frame-by-frame taps)
            'last_direction': 0,  # Track direction to prevent double-navigation
        }

        self.batch_videos_data: List[Dict] = []
        self.batch_overwrite_mode_ui: int = 0  # 0: Skip own, 1: Skip any, 2: Overwrite all
        self.batch_processing_method_idx_ui: int = 0
        self.batch_copy_funscript_to_video_location_ui: bool = True
        self.batch_generate_roll_file_ui: bool = True
        self.batch_apply_ultimate_autotune_ui: bool = True
        self.last_overwrite_mode_ui: int = -1 # Used to trigger auto-selection logic

        # TODO: Move this to a separate class/error management module
        self.error_popup_active = False
        self.error_popup_title = ""
        self.error_popup_message = ""
        self.error_popup_action_label = None
        self.error_popup_action_callback = None

    # --- Worker thread for generating preview images ---
    def _preview_generation_worker(self):
        """
        Runs in a background thread. Waits for tasks and processes them.
        """
        while not self.shutdown_event.is_set():
            try:
                task = self.preview_task_queue.get(timeout=0.1)
                task_type = task['type']

                if task_type == 'timeline':
                    image_data = self._generate_funscript_preview_data(
                        task['target_width'],
                        task['target_height'],
                        task['total_duration_s'],
                        task['actions']
                    )
                    self.preview_results_queue.put({'type': 'timeline', 'image_data': image_data})

                elif task_type == 'heatmap':
                    image_data = self._generate_heatmap_data(
                        task['target_width'],
                        task['target_height'],
                        task['total_duration_s'],
                        task['actions']
                    )
                    self.preview_results_queue.put({'type': 'heatmap', 'image_data': image_data})

                self.preview_task_queue.task_done()

            except queue.Empty:
                continue
            except Exception as e:
                self.app.logger.error(f"Error in preview generation worker: {e}", exc_info=True)

    # --- Method to handle completed preview data from the queue ---
    def _process_preview_results(self):
        """
        Called in the main render loop to process any completed preview images.
        """
        try:
            while not self.preview_results_queue.empty():
                result = self.preview_results_queue.get_nowait()

                result_type = result.get('type')
                image_data = result.get('image_data')

                if image_data is None:
                    continue

                if result_type == 'timeline':
                    self.update_texture(self.funscript_preview_texture_id, image_data)
                elif result_type == 'heatmap':
                    self.update_texture(self.heatmap_texture_id, image_data)

                self.preview_results_queue.task_done()

        except queue.Empty:
            pass  # No results to process
        except Exception as e:
            self.app.logger.error(f"Error processing preview results: {e}", exc_info=True)

    def _handle_threaded_progress(self, task_id: str, progress: float, message: str):
        """Handle progress updates from threaded operations."""
        if task_id in self.active_threaded_operations:
            self.active_threaded_operations[task_id].update({
                'progress': progress,
                'message': message,
                'last_update': time.time()
            })
            
            # Update UI status if this is a high-priority operation
            operation_info = self.active_threaded_operations[task_id]
            if operation_info.get('show_in_status', False):
                status_msg = f"{operation_info.get('name', 'Processing')}: {message} ({progress*100:.1f}%)"
                self.app.set_status_message(status_msg, duration=1.0)

    def submit_async_processing_task(
        self,
        task_id: str,
        task_type: TaskType,
        function,
        args=(),
        kwargs=None,
        priority: TaskPriority = TaskPriority.NORMAL,
        name: str = "Processing",
        show_in_status: bool = True
    ):
        """
        Submit a processing task to run asynchronously without blocking the UI.
        
        Args:
            task_id: Unique identifier for the task
            task_type: Type of processing task
            function: Function to execute
            args: Function arguments
            kwargs: Function keyword arguments
            priority: Task priority
            name: Human-readable name for progress display
            show_in_status: Whether to show progress in status bar
        """
        # Track the operation
        self.active_threaded_operations[task_id] = {
            'name': name,
            'show_in_status': show_in_status,
            'progress': 0.0,
            'message': 'Starting...',
            'started_time': time.time()
        }
        
        # Submit to processing thread manager
        def completion_callback(result):
            # Clean up tracking
            if task_id in self.active_threaded_operations:
                del self.active_threaded_operations[task_id]
            self.app.logger.info(f"Async task {task_id} completed successfully")
        
        def error_callback(error):
            # Clean up tracking and show error
            if task_id in self.active_threaded_operations:
                del self.active_threaded_operations[task_id]
            self.app.logger.error(f"Async task {task_id} failed: {error}")
            self.app.set_status_message(f"Error in {name}: {str(error)}", duration=5.0)
        
        self.processing_thread_manager.submit_task(
            task_id=task_id,
            task_type=task_type,
            function=function,
            args=args,
            kwargs=kwargs or {},
            priority=priority,
            completion_callback=completion_callback,
            error_callback=error_callback
        )
        
        self.app.logger.info(f"Submitted async task: {task_id} ({name})")

    # --- Extracted CPU-intensive drawing logic for timeline ---
    def _generate_funscript_preview_data(self, target_width, target_height, total_duration_s, actions):
        """
        Performs the numpy/cv2 operations to create the timeline image.
        This is called by the worker thread.
        """
        use_simplified_preview = self.app.app_settings.get("use_simplified_funscript_preview", False)

        # Create background
        image_data = np.full((target_height, target_width, 4), (38, 31, 31, 255), dtype=np.uint8)
        center_y_px = target_height // 2
        cv2.line(image_data, (0, center_y_px), (target_width - 1, center_y_px), (77, 77, 77, 179), 1)

        if not actions or total_duration_s <= 0.001:
            return image_data

        if use_simplified_preview:
            if len(actions) < 2: return image_data

            # --- Simplified Min/Max Envelope Drawing ---
            min_vals = np.full(target_width, target_height, dtype=np.int32)
            max_vals = np.full(target_width, -1, dtype=np.int32)

            # Pre-calculate x coordinates and values
            times_s = np.array([a['at'] for a in actions]) / 1000.0
            positions = np.array([a['pos'] for a in actions])
            x_coords = np.round((times_s / total_duration_s) * (target_width - 1)).astype(np.int32)
            y_coords = np.round((1.0 - positions / 100.0) * (target_height - 1)).astype(np.int32)

            # Find min/max y for each x
            for i in range(len(actions) - 1):
                x1, x2 = x_coords[i], x_coords[i+1]
                y1, y2 = y_coords[i], y_coords[i+1]

                if x1 == x2:
                    min_vals[x1] = min(min_vals[x1], y1, y2)
                    max_vals[x1] = max(max_vals[x1], y1, y2)
                else:
                    # Interpolate for line segments
                    dx = x2 - x1
                    dy = y2 - y1
                    for x in range(x1, x2 + 1):
                        y = y1 + dy * (x - x1) / dx
                        y_int = int(round(y))
                        min_vals[x] = min(min_vals[x], y_int)
                        max_vals[x] = max(max_vals[x], y_int)

            # Create polygon points
            min_points = []
            max_points_rev = []
            for x in range(target_width):
                if max_vals[x] != -1: # Only add points where there is data
                    min_points.append([x, min_vals[x]])
                    max_points_rev.append([x, max_vals[x]])

            if not min_points: return image_data

            # Combine to form a closed polygon
            poly_points = np.array(min_points + max_points_rev[::-1], dtype=np.int32)

            # Draw the semi-transparent polygon
            overlay = image_data.copy()
            envelope_color_rgba = self.app.utility.get_speed_color_from_map(500) # Use a mid-range speed color
            envelope_color_bgra = (int(envelope_color_rgba[2] * 255), int(envelope_color_rgba[1] * 255), int(envelope_color_rgba[0] * 255), 100) # 100 for alpha
            cv2.fillPoly(overlay, [poly_points], envelope_color_bgra)
            cv2.addWeighted(overlay, 0.5, image_data, 0.5, 0, image_data) # Blend with background

        else:
            # --- Detailed, Speed-Colored Line Drawing (Original Logic) ---
            if len(actions) > 1:
                ats = np.array([a['at'] for a in actions], dtype=np.float64) / 1000.0
                pos = np.array([a['pos'] for a in actions], dtype=np.float32) / 100.0
                x = np.clip(((ats / total_duration_s) * (target_width - 1)).astype(np.int32), 0, target_width - 1)
                y = np.clip(((1.0 - pos) * target_height).astype(np.int32), 0, target_height - 1)
                dt = np.diff(ats)
                dpos = np.abs(np.diff(pos * 100.0))  # back to 0..100 for speed calc
                speeds = np.divide(dpos, dt, out=np.zeros_like(dpos), where=dt > 1e-6)
                colors_u8 = self.app.utility.get_speed_colors_vectorized_u8(speeds)  # RGBA uint8
                # Draw per segment; allow OpenCV to optimize internally
                for i in range(len(speeds)):
                    if x[i] == x[i+1] and y[i] == y[i+1]:
                        continue
                    c = colors_u8[i]
                    cv2.line(image_data, (int(x[i]), int(y[i])), (int(x[i+1]), int(y[i+1])), (int(c[2]), int(c[1]), int(c[0]), int(c[3])), 1)

        return image_data

    # --- Extracted CPU-intensive drawing logic for heatmap ---
    def _generate_heatmap_data(self, target_width, target_height, total_duration_s, actions):
        """
        Performs the numpy/cv2 operations to create the heatmap image.
        This is called by the worker thread.
        """

        colors = self.colors
        image_data = np.full((target_height, target_width, 4), (colors.HEATMAP_BACKGROUND), dtype=np.uint8)

        if len(actions) > 1 and total_duration_s > 0.001:
            ats = np.array([a['at'] for a in actions], dtype=np.float64) / 1000.0
            poss = np.array([a['pos'] for a in actions], dtype=np.float32)
            # Segment starts/ends in pixel space
            x_coords = ((ats / total_duration_s) * (target_width - 1)).astype(np.int32)
            x_coords = np.clip(x_coords, 0, target_width - 1)
            # Compute speeds per segment
            dt = np.diff(ats)
            dpos = np.abs(np.diff(poss))
            speeds = np.divide(dpos, dt, out=np.zeros_like(dpos), where=dt > 1e-6)
            # Vectorized color mapping (prebuilt cache to uint8)
            colors_u8 = self.app.utility.get_speed_colors_vectorized_u8(speeds)
            # For each column, find its segment index via searchsorted
            cols = np.arange(target_width, dtype=np.int32)
            # Map columns to times then to segment indices
            # In pixel domain we can use x_coords boundaries directly
            seg_idx_for_col = np.searchsorted(x_coords, cols, side='right') - 1
            # Columns before first segment are not-yet-fixed; set fully transparent (alpha=0)
            valid_mask = seg_idx_for_col >= 0
            seg_idx_for_col = np.clip(seg_idx_for_col, 0, len(speeds) - 1)
            col_colors = np.zeros((target_width, 4), dtype=np.uint8)
            if np.any(valid_mask):
                col_colors[valid_mask] = colors_u8[seg_idx_for_col[valid_mask]]  # shape (W,4)
                # Ensure fully opaque for fixed columns
                col_colors[valid_mask, 3] = 255
            # Ensure not-yet-fixed columns remain fully transparent
            if np.any(~valid_mask):
                col_colors[~valid_mask, 3] = 0
            # Broadcast to image rows
            image_data[:] = col_colors[np.newaxis, :, :]

        return image_data

    def _time_render(self, component_name: str, render_func, *args, **kwargs):
        """Helper to time a render function and store its duration."""
        start_time = time.perf_counter()
        render_func(*args, **kwargs)
        end_time = time.perf_counter()
        duration_ms = (end_time - start_time) * 1000
        self.component_render_times[component_name] = duration_ms

        # Accumulate for averaging
        if component_name not in self.perf_accumulated_times:
            self.perf_accumulated_times[component_name] = 0.0
        self.perf_accumulated_times[component_name] += duration_ms

    def get_performance_summary(self):
        """Get comprehensive performance analysis."""
        if not self.component_render_times:
            return {"status": "No performance data available"}
        
        current_total = sum(self.component_render_times.values())
        sorted_components = sorted(
            self.component_render_times.items(),
            key=lambda x: x[1],
            reverse=True
        )
        
        # Categorize performance
        if current_total < 8.33:  # 120 FPS
            status = "EXCELLENT"
            color = (0.0, 1.0, 0.0, 1.0)
        elif current_total < 16.67:  # 60 FPS
            status = "GOOD"
            color = (0.4, 0.8, 0.4, 1.0)
        elif current_total < 33.33:  # 30 FPS
            status = "OK"
            color = (1.0, 0.8, 0.2, 1.0)
        else:
            status = "SLOW"
            color = (1.0, 0.2, 0.2, 1.0)
        
        return {
            "status": status,
            "color": color,
            "total_ms": current_total,
            "components": sorted_components,
            "frame_budget_60fps": 16.67,
            "frame_budget_used_percent": (current_total / 16.67) * 100
        }

    def track_video_decode_time(self, decode_time_ms):
        """Track video decoding performance."""
        self.video_decode_times.append(decode_time_ms)
        self.component_render_times["VideoDecoding"] = decode_time_ms

    def track_disk_io_time(self, operation_name, io_time_ms):
        """Track disk I/O operations."""
        self.disk_io_times.append(io_time_ms)
        self.component_render_times[f"DiskIO_{operation_name}"] = io_time_ms

    def track_network_time(self, operation_name, network_time_ms):
        """Track network operations."""
        self.network_operation_times.append(network_time_ms)
        self.component_render_times[f"Network_{operation_name}"] = network_time_ms

    def update_gpu_memory_usage(self):
        """Update GPU memory usage (called periodically)."""
        try:
            import GPUtil
            gpus = GPUtil.getGPUs()
            if gpus:
                # Get memory usage from first GPU
                gpu = gpus[0]
                self.gpu_memory_usage = gpu.memoryUsed / gpu.memoryTotal * 100
                self.component_render_times["GPU_MemoryUsage"] = self.gpu_memory_usage
            else:
                self.gpu_memory_usage = 0
        except (ImportError, Exception):
            # GPUtil not available or GPU not accessible
            self.gpu_memory_usage = 0

    def _log_performance(self):
        """Log performance statistics and reset accumulators."""
        if not self.perf_accumulated_times or self.perf_frame_count == 0:
            return

        # Calculate averages
        total_time = sum(self.perf_accumulated_times.values())
        avg_time = total_time / self.perf_frame_count if self.perf_frame_count > 0 else 0

        # Build detailed log message
        log_parts = [f"Performance: {avg_time:.2f}ms avg ({self.perf_frame_count} frames)"]
        
        # Sort components by time (most expensive first)
        sorted_components = sorted(
            self.perf_accumulated_times.items(),
            key=lambda x: x[1],
            reverse=True
        )
        
        # Add top 3 most expensive components
        for i, (component, total_time) in enumerate(sorted_components[:3]):
            avg_component_time = total_time / self.perf_frame_count if self.perf_frame_count > 0 else 0
            log_parts.append(f"{component}: {avg_component_time:.2f}ms")
        
        log_message = " | ".join(log_parts)
        self.app.logger.debug(log_message)  # Use debug to avoid spamming info logs

        # Store the current stats in frontend queue before clearing backend
        self._frontend_perf_queue.append({
            'accumulated_times': self.perf_accumulated_times.copy(),
            'frame_count': self.perf_frame_count,
            'timestamp': time.time()
        })
        
        # Clear the backend accumulators for the next interval
        self.perf_accumulated_times.clear()
        self.perf_frame_count = 0
        
        self.last_perf_log_time = time.time()

    def init_glfw(self) -> bool:
        constants = self.constants
        if not glfw.init():
            self.app.logger.error("Could not initialize GLFW")
            return False
        glfw.window_hint(glfw.CONTEXT_VERSION_MAJOR, 3)
        glfw.window_hint(glfw.CONTEXT_VERSION_MINOR, 3)
        glfw.window_hint(glfw.OPENGL_PROFILE, glfw.OPENGL_CORE_PROFILE)
        glfw.window_hint(glfw.OPENGL_FORWARD_COMPAT, gl.GL_TRUE)
        self.window = glfw.create_window(
            self.window_width, self.window_height, constants.APP_WINDOW_TITLE, None, None
        )
        if not self.window:
            glfw.terminate()
            self.app.logger.error("Could not create GLFW window")
            return False

        # Set window icon (macOS doesn't support window icons in GLFW, skip on macOS)
        try:
            import platform
            if platform.system() != "Darwin":  # Skip on macOS
                icon_path = os.path.join(os.path.dirname(__file__), '..', '..', 'assets', 'logo.png')
                if os.path.exists(icon_path):
                    # Load icon with cv2 (already imported)
                    icon_img = cv2.imread(icon_path, cv2.IMREAD_UNCHANGED)
                    if icon_img is not None:
                        # Convert BGR(A) to RGB(A) for GLFW
                        if len(icon_img.shape) == 3 and icon_img.shape[2] == 4:  # Has alpha channel
                            icon_rgb = cv2.cvtColor(icon_img, cv2.COLOR_BGRA2RGBA)
                        else:
                            icon_rgb = cv2.cvtColor(icon_img, cv2.COLOR_BGR2RGB)
                            # Add alpha channel (fully opaque)
                            alpha = np.full((icon_rgb.shape[0], icon_rgb.shape[1], 1), 255, dtype=np.uint8)
                            icon_rgb = np.concatenate([icon_rgb, alpha], axis=2)

                        height, width = icon_rgb.shape[:2]
                        pixels = icon_rgb.tobytes()

                        # pyGLFW expects list of GLFWimage objects
                        # Create image tuple: (width, height, pixels)
                        from glfw import _GLFWimage as GLFWimage
                        icon_image = GLFWimage(width, height, pixels)

                        glfw.set_window_icon(self.window, 1, [icon_image])
                        self.app.logger.debug(f"Window icon set from {icon_path}")
                    else:
                        self.app.logger.warning(f"Failed to load icon image: {icon_path}")
        except Exception as e:
            self.app.logger.debug(f"Window icon not set: {e}")  # Debug level since it's non-critical

        glfw.make_context_current(self.window)
        glfw.set_drop_callback(self.window, self.handle_drop)
        glfw.set_window_close_callback(self.window, self.handle_window_close)

        imgui.create_context()
        self.impl = GlfwRenderer(self.window)
        style = imgui.get_style()
        style.window_rounding = 5.0
        style.frame_rounding = 3.0

        self.frame_texture_id = gl.glGenTextures(1)
        gl.glBindTexture(gl.GL_TEXTURE_2D, self.frame_texture_id)
        gl.glTexParameteri(gl.GL_TEXTURE_2D, gl.GL_TEXTURE_MIN_FILTER, gl.GL_LINEAR)
        gl.glTexParameteri(gl.GL_TEXTURE_2D, gl.GL_TEXTURE_MAG_FILTER, gl.GL_LINEAR)
        gl.glTexParameteri(gl.GL_TEXTURE_2D, gl.GL_TEXTURE_WRAP_S, gl.GL_CLAMP_TO_EDGE)
        gl.glTexParameteri(gl.GL_TEXTURE_2D, gl.GL_TEXTURE_WRAP_T, gl.GL_CLAMP_TO_EDGE)
        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)

        # Initialize heatmap with a dummy texture
        self.heatmap_texture_id = gl.glGenTextures(1)
        gl.glBindTexture(gl.GL_TEXTURE_2D, self.heatmap_texture_id)
        gl.glTexParameteri(gl.GL_TEXTURE_2D, gl.GL_TEXTURE_MIN_FILTER, gl.GL_NEAREST)
        gl.glTexParameteri(gl.GL_TEXTURE_2D, gl.GL_TEXTURE_MAG_FILTER, gl.GL_NEAREST)
        dummy_pixel = np.array([0, 0, 0, 0], dtype=np.uint8).tobytes()
        gl.glTexImage2D(gl.GL_TEXTURE_2D, 0, gl.GL_RGBA, 1, 1, 0, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, dummy_pixel)
        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)

        # Initialize funscript preview with a dummy texture
        self.funscript_preview_texture_id = gl.glGenTextures(1)
        gl.glBindTexture(gl.GL_TEXTURE_2D, self.funscript_preview_texture_id)
        gl.glTexParameteri(gl.GL_TEXTURE_2D, gl.GL_TEXTURE_MIN_FILTER, gl.GL_NEAREST)
        gl.glTexParameteri(gl.GL_TEXTURE_2D, gl.GL_TEXTURE_MAG_FILTER, gl.GL_NEAREST)
        gl.glTexParameteri(gl.GL_TEXTURE_2D, gl.GL_TEXTURE_WRAP_S, gl.GL_CLAMP_TO_EDGE)
        gl.glTexParameteri(gl.GL_TEXTURE_2D, gl.GL_TEXTURE_WRAP_T, gl.GL_CLAMP_TO_EDGE)
        dummy_pixel_fs_preview = np.array([0, 0, 0, 0], dtype=np.uint8).tobytes()
        gl.glTexImage2D(gl.GL_TEXTURE_2D, 0, gl.GL_RGBA, 1, 1, 0, gl.GL_RGBA, gl.GL_UNSIGNED_BYTE, dummy_pixel_fs_preview)
        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)

        # Initialize dedicated enhanced preview texture (isolated from main video display)
        self.enhanced_preview_texture_id = gl.glGenTextures(1)
        gl.glBindTexture(gl.GL_TEXTURE_2D, self.enhanced_preview_texture_id)
        gl.glTexParameteri(gl.GL_TEXTURE_2D, gl.GL_TEXTURE_MIN_FILTER, gl.GL_LINEAR)
        gl.glTexParameteri(gl.GL_TEXTURE_2D, gl.GL_TEXTURE_MAG_FILTER, gl.GL_LINEAR)
        gl.glTexParameteri(gl.GL_TEXTURE_2D, gl.GL_TEXTURE_WRAP_S, gl.GL_CLAMP_TO_EDGE)
        gl.glTexParameteri(gl.GL_TEXTURE_2D, gl.GL_TEXTURE_WRAP_T, gl.GL_CLAMP_TO_EDGE)
        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)
        return True

    def handle_window_close(self, window):
        """Handle window close event (X button clicked)."""
        self.app.logger.info("Window close requested via window controls")
        self.app.shutdown_app()

    def handle_drop(self, window, paths):
        if not paths:
            return

        constants = self.constants

        # Separate files by type
        project_files = [p for p in paths if p.lower().endswith(constants.PROJECT_FILE_EXTENSION)]
        funscript_files = [p for p in paths if p.lower().endswith('.funscript')]
        other_files = [p for p in paths if p not in project_files and p not in funscript_files]

        # 1. Handle Project Files (highest priority)
        if project_files:
            project_to_load = project_files[0]
            self.app.logger.info(f"Project file dropped. Loading: {os.path.basename(project_to_load)}")
            self.app.project_manager.load_project(project_to_load)
            # Typically, loading a project handles everything, so we can stop.
            return

        # 2. Handle Video/Other Files via FileManager
        if other_files:
            self.app.logger.info(f"Video/other files dropped. Passing to FileManager: {len(other_files)} files")
            # This will handle loading the video and preparing the processor
            self.app.file_manager.handle_drop_event(other_files)

        # 3. Handle Funscript Files
        if funscript_files:
            self.app.logger.info(f"Funscript files dropped: {len(funscript_files)} files")
            # If timeline 1 is empty or has no AI-generated script, load the first funscript there.

            if not self.app.funscript_processor.get_actions('primary'):
                self.app.logger.info(f"Loading '{os.path.basename(funscript_files[0])}' into Timeline 1.")
                self.app.file_manager.load_funscript_to_timeline(funscript_files[0], timeline_num=1)

                if len(funscript_files) > 1:
                    self.app.logger.info(f"Loading '{os.path.basename(funscript_files[1])}' into Timeline 2.")
                    self.app.file_manager.load_funscript_to_timeline(funscript_files[1], timeline_num=2)
                    self.app.app_state_ui.show_funscript_interactive_timeline2 = True
            else:
                self.app.logger.info(f"Timeline 1 has data. Loading '{os.path.basename(funscript_files[0])}' into Timeline 2.")
                self.app.file_manager.load_funscript_to_timeline(funscript_files[0], timeline_num=2)
                self.app.app_state_ui.show_funscript_interactive_timeline2 = True

            # Mark previews as dirty to force a redraw
            self.app.app_state_ui.funscript_preview_dirty = True
            self.app.app_state_ui.heatmap_dirty = True


    def update_texture(self, texture_id: int, image: np.ndarray):
        if image is None or image.size == 0: return
        h, w = image.shape[:2]
        if w == 0 or h == 0: return

        # Ensure we have a valid texture ID
        if not gl.glIsTexture(texture_id):
            self.app.logger.error(f"Attempted to update an invalid texture ID: {texture_id}")
            return

        gl.glBindTexture(gl.GL_TEXTURE_2D, texture_id)

        # Cache last texture sizes to prefer glTexSubImage2D when dimensions unchanged
        if not hasattr(self, '_texture_sizes'):
            self._texture_sizes = {}

        last_size = self._texture_sizes.get(texture_id)

        # Determine format and upload
        if len(image.shape) == 2:
            internal_fmt = gl.GL_RED; fmt = gl.GL_RED; payload = image
        elif image.shape[2] == 3:
            internal_fmt = gl.GL_RGB; fmt = gl.GL_RGB; payload = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        else:
            internal_fmt = gl.GL_RGBA; fmt = gl.GL_RGBA; payload = image

        if last_size and last_size == (w, h, internal_fmt):
            gl.glTexSubImage2D(gl.GL_TEXTURE_2D, 0, 0, 0, w, h, fmt, gl.GL_UNSIGNED_BYTE, payload)
        else:
            gl.glTexImage2D(gl.GL_TEXTURE_2D, 0, internal_fmt, w, h, 0, fmt, gl.GL_UNSIGNED_BYTE, payload)
            self._texture_sizes[texture_id] = (w, h, internal_fmt)

        gl.glBindTexture(gl.GL_TEXTURE_2D, 0)

    def _render_energy_saver_indicator(self):
        colors = self.colors
        """Renders a constant indicator when energy saver mode is active."""
        if self.app.energy_saver.energy_saver_active:
            indicator_text = "Energy Saver Active"
            main_viewport = imgui.get_main_viewport()
            style = imgui.get_style()
            text_size = imgui.calc_text_size(indicator_text)

            # Account for icon size (16x16) + spacing
            icon_width = 20  # 16px icon + 4px spacing
            win_size = (text_size[0] + icon_width + style.window_padding[0] * 2,
                       max(text_size[1], 16) + style.window_padding[1] * 2)
            position = (main_viewport.pos[0] + 10, main_viewport.pos[1] + main_viewport.size[1] - win_size[1] - 10)

            imgui.set_next_window_position(position[0], position[1])
            imgui.set_next_window_bg_alpha(0.65)

            window_flags = (imgui.WINDOW_NO_DECORATION |
                            imgui.WINDOW_NO_MOVE |
                            imgui.WINDOW_ALWAYS_AUTO_RESIZE |
                            imgui.WINDOW_NO_INPUTS |
                            imgui.WINDOW_NO_FOCUS_ON_APPEARING |
                            imgui.WINDOW_NO_NAV)

            imgui.begin("EnergySaverIndicator", closable=False, flags=window_flags)

            # Show leaf icon + text
            icon_mgr = getattr(self, 'icon_manager', None)
            if icon_mgr:
                leaf_tex, _, _ = icon_mgr.get_icon_texture('energy-leaf.png')
                if leaf_tex:
                    imgui.image(leaf_tex, 16, 16)
                    imgui.same_line()

            imgui.text_colored(indicator_text, *colors.ENERGY_SAVER_INDICATOR)
            imgui.end()

    # --- This function now submits a task to the worker thread ---
    def render_funscript_timeline_preview(self, total_duration_s: float, graph_height: int):
        app_state = self.app.app_state_ui
        colors = self.colors
        style = imgui.get_style()

        current_bar_width_float = imgui.get_content_region_available()[0]
        current_bar_width_int = int(round(current_bar_width_float))

        if current_bar_width_int <= 0 or graph_height <= 0 or not self.funscript_preview_texture_id:
            imgui.dummy(current_bar_width_float if current_bar_width_float > 0 else 1, graph_height + 5)
            return

        current_action_count = len(self.app.funscript_processor.get_actions('primary'))
        is_live_tracking = self.app.processor and self.app.processor.tracker and self.app.processor.tracker.tracking_active

        # Determine if a redraw is needed
        full_redraw_needed = (app_state.funscript_preview_dirty
            or current_bar_width_int != app_state.last_funscript_preview_bar_width
            or abs(total_duration_s - app_state.last_funscript_preview_duration_s) > 0.01)

        incremental_update_needed = current_action_count != self.last_submitted_action_count_timeline

        # For this async model, we always do a full redraw. Incremental drawing is complex with threading.
        # The performance gain from async outweighs the loss of incremental drawing.
        needs_regen = (full_redraw_needed
            or (incremental_update_needed
            and (not is_live_tracking
            or (time.time() - self.last_preview_update_time_timeline >= self.preview_update_interval_seconds))))

        # Non-blocking submit: try_put; if queue full, skip this frame without blocking UI
        if needs_regen:
            actions_copy = self.app.funscript_processor.get_actions('primary').copy()
            task = {
                'type': 'timeline',
                'target_width': current_bar_width_int,
                'target_height': graph_height,
                'total_duration_s': total_duration_s,
                'actions': actions_copy
            }
            try:
                self.preview_task_queue.put_nowait(task)
            except queue.Full:
                pass

            # Update state after submission
            app_state.funscript_preview_dirty = False
            app_state.last_funscript_preview_bar_width = current_bar_width_int
            app_state.last_funscript_preview_duration_s = total_duration_s
            self.last_submitted_action_count_timeline = current_action_count
            if is_live_tracking and incremental_update_needed:
                self.last_preview_update_time_timeline = time.time()

        # --- Rendering Logic (uses the existing texture until a new one is ready) ---
        imgui.set_cursor_pos_y(imgui.get_cursor_pos_y() + 20)
        canvas_p1_x = imgui.get_cursor_screen_pos()[0]
        canvas_p1_y_offset = imgui.get_cursor_screen_pos()[1]

        imgui.image(self.funscript_preview_texture_id, current_bar_width_float, graph_height, uv0=(0, 0), uv1=(1, 1))

        # --- Add seeking capability to the funscript preview bar ---
        if imgui.is_item_hovered():
            mouse_x = imgui.get_mouse_pos()[0] - canvas_p1_x
            normalized_pos = np.clip(mouse_x / current_bar_width_float, 0.0, 1.0)
            if self.app.processor and self.app.processor.video_info:
                total_frames = self.app.processor.video_info.get('total_frames', 0)
                if total_frames > 0:
                    if (imgui.is_mouse_dragging(0) or imgui.is_mouse_down(0)):
                        # Use time-based calculation consistent with timeline and funscript timing
                        click_time_s = normalized_pos * total_duration_s
                        fps = self.app.processor.fps if self.app.processor and self.app.processor.fps > 0 else 30.0
                        seek_frame = int(round(click_time_s * fps))
                        seek_frame = max(0, min(seek_frame, total_frames - 1))  # Clamp to valid range
                        
                        self.app.event_handlers.handle_seek_bar_drag(seek_frame)
                    else:
                        # Show enhanced tooltip with zoom preview and video frame
                        total_duration = total_duration_s  # Use the parameter passed to this function
                        if total_duration > 0:
                            hover_time_s = normalized_pos * total_duration
                            # Use consistent time-based frame calculation for hover too
                            fps = self.app.processor.fps if self.app.processor and self.app.processor.fps > 0 else 30.0
                            hover_frame = int(round(hover_time_s * fps))
                            hover_frame = max(0, min(hover_frame, total_frames - 1))
                            
                            # Initialize hover tracking attributes if needed
                            if not hasattr(self, '_preview_hover_start_time'):
                                self._preview_hover_start_time = None
                                self._preview_hover_pos = None
                                self._preview_cached_tooltip_data = None
                                self._preview_cached_pos = None
                            
                            # Use much tighter tolerance to avoid frame/video mismatches
                            # With 10k frames, 0.0001 = ~1 frame tolerance instead of ~50 frames
                            position_tolerance = 0.0001  # ~0.01% tolerance for position stability
                            position_changed = (self._preview_hover_pos is None or 
                                              abs(self._preview_hover_pos - normalized_pos) > position_tolerance)
                            
                            if position_changed:
                                self._preview_hover_pos = normalized_pos
                                self._preview_hover_start_time = time.time()
                                # Clear cached data when position changes
                                self._preview_cached_tooltip_data = None
                                self._preview_cached_pos = None
                            
                            # Show enhanced preview logic
                            hover_duration = time.time() - self._preview_hover_start_time if self._preview_hover_start_time else 0
                            enhanced_preview_enabled = self.app.app_settings.get("enable_enhanced_funscript_preview", True)
                            
                            if enhanced_preview_enabled:
                                # Always show timestamp + script zoom instantly, then add video frame after delay
                                show_video_frame = hover_duration > 0.3  # Video frame only after 300ms for responsiveness
                                
                                # Check if we have cached data for this position (with tight tolerance)
                                if (self._preview_cached_tooltip_data is not None and 
                                    self._preview_cached_pos is not None and 
                                    abs(self._preview_cached_pos - normalized_pos) <= position_tolerance):
                                    
                                    # If we need video frame but cached data doesn't have it, fetch async
                                    cached_frame_data = self._preview_cached_tooltip_data.get('frame_data')
                                    if show_video_frame and (cached_frame_data is None or cached_frame_data.size == 0):
                                        # Check if we already have a pending fetch for this frame
                                        if not hasattr(self, '_preview_frame_fetch_pending'):
                                            self._preview_frame_fetch_pending = False

                                        if not self._preview_frame_fetch_pending:
                                            # Start async fetch in background thread
                                            self._preview_frame_fetch_pending = True
                                            self._preview_cached_tooltip_data['frame_loading'] = True  # Set immediately so tooltip shows "Loading..."
                                            cached_hover_frame = self._preview_cached_tooltip_data.get('hover_frame', hover_frame)

                                            def fetch_frame_async():
                                                try:
                                                    frame_data, actual_frame = self._get_frame_direct_cv2(cached_hover_frame)
                                                    if frame_data is not None and frame_data.size > 0:
                                                        self._preview_cached_tooltip_data['frame_data'] = frame_data
                                                        self._preview_cached_tooltip_data['actual_frame'] = actual_frame
                                                        self._preview_cached_tooltip_data['frame_loading'] = False
                                                except Exception:
                                                    self._preview_cached_tooltip_data['frame_loading'] = False
                                                finally:
                                                    self._preview_frame_fetch_pending = False

                                            import threading
                                            threading.Thread(target=fetch_frame_async, daemon=True).start()
                                    
                                    # Use cached tooltip data (frame number and video frame are consistent)
                                    self._render_instant_enhanced_tooltip(self._preview_cached_tooltip_data, show_video_frame)
                                else:
                                    # Generate new tooltip data (without slow video frame extraction initially)
                                    try:
                                        tooltip_data = self._generate_instant_tooltip_data(
                                            hover_time_s, hover_frame, total_duration, normalized_pos, show_video_frame
                                        )
                                        self._preview_cached_tooltip_data = tooltip_data
                                        self._preview_cached_pos = normalized_pos

                                        # Launch async frame fetch if needed
                                        if show_video_frame and tooltip_data.get('frame_loading', False):
                                            if not hasattr(self, '_preview_frame_fetch_pending'):
                                                self._preview_frame_fetch_pending = False

                                            if not self._preview_frame_fetch_pending:
                                                self._preview_frame_fetch_pending = True

                                                def fetch_frame_async():
                                                    try:
                                                        frame_data, actual_frame = self._get_frame_direct_cv2(hover_frame)
                                                        if frame_data is not None and frame_data.size > 0:
                                                            self._preview_cached_tooltip_data['frame_data'] = frame_data
                                                            self._preview_cached_tooltip_data['actual_frame'] = actual_frame
                                                            self._preview_cached_tooltip_data['frame_loading'] = False
                                                    except Exception:
                                                        self._preview_cached_tooltip_data['frame_loading'] = False
                                                    finally:
                                                        self._preview_frame_fetch_pending = False

                                                import threading
                                                threading.Thread(target=fetch_frame_async, daemon=True).start()

                                        self._render_instant_enhanced_tooltip(tooltip_data, show_video_frame)
                                    except Exception as e:
                                        # Fallback to simple tooltip
                                        imgui.set_tooltip(f"{_format_time(self.app, hover_time_s)} / {_format_time(self.app, total_duration)}")
                            else:
                                # Show simple time tooltip immediately
                                imgui.set_tooltip(f"{_format_time(self.app, hover_time_s)} / {_format_time(self.app, total_duration)}")
        else:
            # Reset hover tracking when mouse leaves
            if hasattr(self, '_preview_hover_start_time'):
                self._preview_hover_start_time = None
                self._preview_hover_pos = None
                self._preview_frame_fetch_pending = False

        # Draw playback marker over the image
        if self.app.file_manager.video_path and self.app.processor and self.app.processor.video_info and self.app.processor.current_frame_index >= 0:
            total_frames = self.app.processor.video_info.get('total_frames', 0)
            if total_frames > 0:
                # Use time-based calculation for consistency with timeline and seeking
                fps = self.app.processor.fps if self.app.processor.fps > 0 else 30.0
                current_time_s = self.app.processor.current_frame_index / fps
                normalized_pos = current_time_s / total_duration_s if total_duration_s > 0 else 0
                marker_x = (canvas_p1_x + style.frame_padding[0]) + (normalized_pos * (current_bar_width_float - style.frame_padding[0] * 2))
                marker_color = imgui.get_color_u32_rgba(*colors.MARKER)
                draw_list_marker = imgui.get_window_draw_list()

                # Draw triangle
                triangle_p1 = (marker_x - 5, canvas_p1_y_offset)
                triangle_p2 = (marker_x + 5, canvas_p1_y_offset)
                triangle_p3 = (marker_x, canvas_p1_y_offset + 5)
                draw_list_marker.add_triangle_filled(triangle_p1[0], triangle_p1[1], triangle_p2[0], triangle_p2[1], triangle_p3[0], triangle_p3[1], marker_color)

                # Draw line
                draw_list_marker.add_line(marker_x, canvas_p1_y_offset, marker_x, canvas_p1_y_offset + graph_height, marker_color, 1.0)

                # Draw text
                current_frame = self.app.processor.current_frame_index
                current_time_s = self.app.processor.current_frame_index / self.app.processor.video_info.get('fps', 30.0)
                text = f"{_format_time(self.app, current_time_s)} ({current_frame})"
                text_size = imgui.calc_text_size(text)
                text_pos_x = marker_x - text_size[0] / 2
                if text_pos_x < canvas_p1_x:
                    text_pos_x = canvas_p1_x
                if text_pos_x + text_size[0] > canvas_p1_x + current_bar_width_float:
                    text_pos_x = canvas_p1_x + current_bar_width_float - text_size[0]
                text_pos = (text_pos_x, canvas_p1_y_offset - text_size[1] - 2)
                draw_list_marker.add_text(text_pos[0], text_pos[1], imgui.get_color_u32_rgba(*colors.WHITE), text)


    # --- This function now submits a task to the worker thread ---
    def render_funscript_heatmap_preview(self, total_video_duration_s: float, bar_width_float: float, bar_height_float: float):
        app_state = self.app.app_state_ui
        current_bar_width_int = int(round(bar_width_float))
        if current_bar_width_int <= 0 or app_state.heatmap_texture_fixed_height <= 0 or not self.heatmap_texture_id:
            imgui.dummy(bar_width_float, bar_height_float)
            return

        current_action_count = len(self.app.funscript_processor.get_actions('primary'))
        is_live_tracking = self.app.processor and self.app.processor.tracker and self.app.processor.tracker.tracking_active

        full_redraw_needed = (
            app_state.heatmap_dirty
            or current_bar_width_int != app_state.last_heatmap_bar_width
            or abs(total_video_duration_s - app_state.last_heatmap_video_duration_s) > 0.01)

        incremental_update_needed = current_action_count != self.last_submitted_action_count_heatmap

        needs_regen = full_redraw_needed or (incremental_update_needed and (not is_live_tracking or (time.time() - self.last_preview_update_time_heatmap >= self.preview_update_interval_seconds)))

        if needs_regen:
            actions_copy = self.app.funscript_processor.get_actions('primary').copy()
            task = {
                'type': 'heatmap',
                'target_width': current_bar_width_int,
                'target_height': app_state.heatmap_texture_fixed_height,
                'total_duration_s': total_video_duration_s,
                'actions': actions_copy
            }
            try:
                self.preview_task_queue.put_nowait(task)
            except queue.Full:
                pass

            # Update state after submission
            app_state.heatmap_dirty = False
            app_state.last_heatmap_bar_width = current_bar_width_int
            app_state.last_heatmap_video_duration_s = total_video_duration_s
            self.last_submitted_action_count_heatmap = current_action_count
            if is_live_tracking and incremental_update_needed:
                self.last_preview_update_time_heatmap = time.time()

        # Render the existing texture
        imgui.image(self.heatmap_texture_id, bar_width_float, bar_height_float, uv0=(0, 0), uv1=(1, 1))

    def _render_first_run_setup_popup(self):
        # Disabled automatic model downloading - now handled manually via AI menu
        pass
        # app = self.app
        # if app.show_first_run_setup_popup:
        #     imgui.open_popup("First-Time Setup")
        #     main_viewport = imgui.get_main_viewport()
        #     popup_pos = (main_viewport.pos[0] + main_viewport.size[0] * 0.5,
        #                  main_viewport.pos[1] + main_viewport.size[1] * 0.5)
        #     imgui.set_next_window_position(popup_pos[0], popup_pos[1], pivot_x=0.5, pivot_y=0.5)

        #     # Make the popup non-closable by the user until setup is done or fails.
        #     closable = "complete" in app.first_run_status_message or "failed" in app.first_run_status_message
        #     popup_flags = imgui.WINDOW_ALWAYS_AUTO_RESIZE | (0 if not closable else imgui.WINDOW_CLOSABLE)

        #     if imgui.begin_popup_modal("First-Time Setup", closable, flags=popup_flags)[0]:
        #         imgui.text("Welcome to FunGen!")
        #         imgui.text_wrapped("For the application to work, some default AI models need to be downloaded.")
        #         imgui.separator()

        #         imgui.text_wrapped(f"Status: {app.first_run_status_message}")

        #         # Progress Bar
        #         progress_percent = app.first_run_progress / 100.0
        #         imgui.progress_bar(progress_percent, size=(350, 0), overlay=f"{app.first_run_progress:.1f}%")

        #         imgui.separator()

        #         if closable:
        #             if imgui.button("Close", width=120):
        #                 app.show_first_run_setup_popup = False
        #                 imgui.close_current_popup()

        #         imgui.end_popup()


    # TODO: Move this to a separate class/error management module
    def show_error_popup(self, title, message, action_label=None, action_callback=None):
        self.error_popup_active = True
        self.error_popup_title = title
        self.error_popup_message = message
        self.error_popup_action_label = action_label
        self.error_popup_action_callback = action_callback

    # All other methods from the original file from this point are included below without modification
    # for completeness, except for the `run` method's `finally` block which now handles thread shutdown.

    def _draw_fps_marks_on_slider(self, draw_list, min_rect, max_rect, current_target_fps, tracker_fps, processor_fps):
        if not imgui.is_item_visible():
            return

        app_state = self.app.app_state_ui
        colors = self.colors
        marks = [(current_target_fps, colors.FPS_TARGET_MARKER, "Target"), (tracker_fps, colors.FPS_TRACKER_MARKER, "Tracker"), (processor_fps, colors.FPS_PROCESSOR_MARKER, "Processor")]
        slider_x_start, slider_x_end = min_rect.x, max_rect.x
        slider_width = slider_x_end - slider_x_start
        slider_y = (min_rect.y + max_rect.y) / 2
        for mark_fps, color_rgb, label_text in marks:
            if not (app_state.fps_slider_min_val <= mark_fps <= app_state.fps_slider_max_val): continue
            norm = (mark_fps - app_state.fps_slider_min_val) / (
                    app_state.fps_slider_max_val - app_state.fps_slider_min_val)
            x_pos = slider_x_start + norm * slider_width
            color_u32 = imgui.get_color_u32_rgba(color_rgb[0] / 255, color_rgb[1] / 255, color_rgb[2] / 255, 1.0)
            draw_list.add_line(x_pos, slider_y - 6, x_pos, slider_y + 6, color_u32, thickness=1.5)

    def _handle_global_shortcuts(self):
        # CRITICAL: Check if shortcuts should be processed
        # This prevents shortcuts from firing when user is typing in text inputs
        if not self.app.shortcut_manager.should_handle_shortcuts():
            return

        io = imgui.get_io()
        app_state = self.app.app_state_ui

        current_shortcuts = self.app.app_settings.get("funscript_editor_shortcuts", {})
        fs_proc = self.app.funscript_processor
        video_loaded = self.app.processor and self.app.processor.video_info and self.app.processor.total_frames > 0

        def check_and_run_shortcut(shortcut_name, action_func, *action_args):
            shortcut_str = current_shortcuts.get(shortcut_name)
            if not shortcut_str:
                return False

            map_result = self.app._map_shortcut_to_glfw_key(shortcut_str)
            if not map_result:
                return False

            mapped_key, mapped_mods_from_string = map_result

            # Check key press state ONCE and reuse (calling is_key_pressed multiple times can consume the event)
            key_pressed = imgui.is_key_pressed(mapped_key)

            if key_pressed:
                mods_match = (mapped_mods_from_string['ctrl'] == io.key_ctrl
                    and mapped_mods_from_string['alt'] == io.key_alt
                    and mapped_mods_from_string['shift'] == io.key_shift
                    and mapped_mods_from_string['super'] == io.key_super)
                if mods_match:
                    action_func(*action_args)
                    return True
            return False

        def check_key_held(shortcut_name):
            """Check if a key is being held down (for continuous navigation)"""
            shortcut_str = current_shortcuts.get(shortcut_name)
            if not shortcut_str:
                return False
            map_result = self.app._map_shortcut_to_glfw_key(shortcut_str)
            if not map_result:
                return False
            mapped_key, mapped_mods_from_string = map_result
            return (imgui.is_key_down(mapped_key) and
                   mapped_mods_from_string['ctrl'] == io.key_ctrl and
                   mapped_mods_from_string['alt'] == io.key_alt and
                   mapped_mods_from_string['shift'] == io.key_shift and
                   mapped_mods_from_string['super'] == io.key_super)

        # F1 key - Open Keyboard Shortcuts Dialog (no modifiers)
        f1_map = self.app._map_shortcut_to_glfw_key("F1")
        if f1_map:
            f1_key, f1_mods = f1_map
            if (imgui.is_key_pressed(f1_key) and
                not io.key_ctrl and not io.key_alt and not io.key_shift and not io.key_super):
                self.keyboard_shortcuts_dialog.toggle()
                return

        # Handle non-repeating shortcuts first

        # File Operations
        if check_and_run_shortcut("save_project", self._handle_save_project_shortcut):
            pass
        elif check_and_run_shortcut("open_project", self._handle_open_project_shortcut):
            pass

        # Editing
        elif check_and_run_shortcut("undo_timeline1", fs_proc.perform_undo_redo, 1, 'undo'):
            pass
        elif check_and_run_shortcut("redo_timeline1", fs_proc.perform_undo_redo, 1, 'redo'):
            pass
        elif self.app.app_state_ui.show_funscript_interactive_timeline2 and (
            check_and_run_shortcut("undo_timeline2", fs_proc.perform_undo_redo, 2, 'undo')
            or check_and_run_shortcut("redo_timeline2", fs_proc.perform_undo_redo, 2, 'redo')
        ): pass

        # Playback & Navigation
        elif check_and_run_shortcut("toggle_playback", self.app.event_handlers.handle_playback_control, "play_pause"):
            pass
        elif check_and_run_shortcut("jump_to_next_point", self.app.event_handlers.handle_jump_to_point, 'next'):
            pass
        elif check_and_run_shortcut("jump_to_next_point_alt", self.app.event_handlers.handle_jump_to_point, 'next'):
            pass
        elif check_and_run_shortcut("jump_to_prev_point", self.app.event_handlers.handle_jump_to_point, 'prev'):
            pass
        elif check_and_run_shortcut("jump_to_prev_point_alt", self.app.event_handlers.handle_jump_to_point, 'prev'):
            pass
        elif video_loaded and check_and_run_shortcut("jump_to_start", self._handle_jump_to_start_shortcut):
            pass
        elif video_loaded and check_and_run_shortcut("jump_to_end", self._handle_jump_to_end_shortcut):
            pass

        # Timeline View Controls
        elif check_and_run_shortcut("zoom_in_timeline", self._handle_zoom_in_timeline_shortcut):
            pass
        elif check_and_run_shortcut("zoom_out_timeline", self._handle_zoom_out_timeline_shortcut):
            pass

        # Window Toggles
        elif check_and_run_shortcut("toggle_video_display", self._handle_toggle_video_display_shortcut):
            pass
        elif check_and_run_shortcut("toggle_timeline2", self._handle_toggle_timeline2_shortcut):
            pass
        elif check_and_run_shortcut("toggle_gauge_window", self._handle_toggle_gauge_window_shortcut):
            pass
        elif check_and_run_shortcut("toggle_3d_simulator", self._handle_toggle_3d_simulator_shortcut):
            pass
        elif check_and_run_shortcut("toggle_movement_bar", self._handle_toggle_movement_bar_shortcut):
            pass
        elif check_and_run_shortcut("toggle_chapter_list", self._handle_toggle_chapter_list_shortcut):
            pass

        # Timeline Displays
        elif check_and_run_shortcut("toggle_heatmap", self._handle_toggle_heatmap_shortcut):
            pass
        elif check_and_run_shortcut("toggle_funscript_preview", self._handle_toggle_funscript_preview_shortcut):
            pass

        # Video Overlays
        elif check_and_run_shortcut("toggle_video_feed", self._handle_toggle_video_feed_shortcut):
            pass
        elif check_and_run_shortcut("toggle_waveform", self._handle_toggle_waveform_shortcut):
            pass

        # View Controls
        elif check_and_run_shortcut("reset_timeline_view", self._handle_reset_timeline_view_shortcut):
            pass

        # Chapters
        elif check_and_run_shortcut("set_chapter_start", self._handle_set_chapter_start_shortcut):
            pass
        elif check_and_run_shortcut("set_chapter_end", self._handle_set_chapter_end_shortcut):
            pass

        # Add Points at specific values (Number keys 0-9 and = for 100%)
        # These add a point at the current video time to the active timeline
        if video_loaded and check_and_run_shortcut("add_point_0", self._handle_add_point_at_value, 0):
            pass
        elif video_loaded and check_and_run_shortcut("add_point_10", self._handle_add_point_at_value, 10):
            pass
        elif video_loaded and check_and_run_shortcut("add_point_20", self._handle_add_point_at_value, 20):
            pass
        elif video_loaded and check_and_run_shortcut("add_point_30", self._handle_add_point_at_value, 30):
            pass
        elif video_loaded and check_and_run_shortcut("add_point_40", self._handle_add_point_at_value, 40):
            pass
        elif video_loaded and check_and_run_shortcut("add_point_50", self._handle_add_point_at_value, 50):
            pass
        elif video_loaded and check_and_run_shortcut("add_point_60", self._handle_add_point_at_value, 60):
            pass
        elif video_loaded and check_and_run_shortcut("add_point_70", self._handle_add_point_at_value, 70):
            pass
        elif video_loaded and check_and_run_shortcut("add_point_80", self._handle_add_point_at_value, 80):
            pass
        elif video_loaded and check_and_run_shortcut("add_point_90", self._handle_add_point_at_value, 90):
            pass
        elif video_loaded and check_and_run_shortcut("add_point_100", self._handle_add_point_at_value, 100):
            pass

        # Handle continuous arrow key navigation
        if video_loaded:
            self._handle_arrow_navigation()

    def _handle_arrow_navigation(self):
        """Optimized arrow key navigation with continuous scrolling support"""
        io = imgui.get_io()
        current_shortcuts = self.app.app_settings.get("funscript_editor_shortcuts", {})
        current_time = time.time()
        
        # Update seek interval based on video FPS for natural navigation speed
        if self.app.processor and self.app.processor.fps > 0:
            # Use video FPS but cap at reasonable limits for responsiveness
            video_fps = self.app.processor.fps
            # Allow faster navigation for high FPS videos, slower for low FPS
            target_nav_fps = max(15, min(60, video_fps))  
            self.arrow_key_state['seek_interval'] = 1.0 / target_nav_fps
        
        # Get arrow key mappings
        left_shortcut = current_shortcuts.get("seek_prev_frame", "LEFT_ARROW")
        right_shortcut = current_shortcuts.get("seek_next_frame", "RIGHT_ARROW")
        
        left_map = self.app._map_shortcut_to_glfw_key(left_shortcut)
        right_map = self.app._map_shortcut_to_glfw_key(right_shortcut)
        
        if not left_map or not right_map:
            return
            
        left_key, left_mods = left_map
        right_key, right_mods = right_map
        
        # Check if keys are held down (no modifier keys for arrow navigation)
        left_held = (imgui.is_key_down(left_key) and 
                    left_mods['ctrl'] == io.key_ctrl and
                    left_mods['alt'] == io.key_alt and
                    left_mods['shift'] == io.key_shift and
                    left_mods['super'] == io.key_super)
        
        right_held = (imgui.is_key_down(right_key) and 
                     right_mods['ctrl'] == io.key_ctrl and
                     right_mods['alt'] == io.key_alt and
                     right_mods['shift'] == io.key_shift and
                     right_mods['super'] == io.key_super)
        
        # Update key state
        self.arrow_key_state['left_pressed'] = left_held
        self.arrow_key_state['right_pressed'] = right_held
        
        # Determine seek direction and apply rate limiting
        seek_direction = 0
        if left_held and not right_held:
            seek_direction = -1
        elif right_held and not left_held:
            seek_direction = 1

        # Reset direction tracking when key is released
        if seek_direction == 0:
            self.arrow_key_state['last_direction'] = 0

        # Apply navigation with proper frame-by-frame then continuous logic
        if seek_direction != 0:
            time_since_last = current_time - self.arrow_key_state['last_seek_time']
            key_just_pressed = (left_held and imgui.is_key_pressed(left_key)) or (right_held and imgui.is_key_pressed(right_key))

            should_navigate = False

            if key_just_pressed:
                # INITIAL KEY PRESS: Only navigate if this is a new direction
                if self.arrow_key_state['last_direction'] != seek_direction:
                    should_navigate = True
                    self.arrow_key_state['initial_press_time'] = current_time
                    self.arrow_key_state['last_direction'] = seek_direction
            else:
                # KEY HELD DOWN: Only allow if already in an active key session
                if self.arrow_key_state['last_direction'] == seek_direction:
                    time_since_initial_press = current_time - self.arrow_key_state['initial_press_time']

                    if time_since_initial_press >= self.arrow_key_state['continuous_delay']:
                        # Continuous scrolling: only navigate after interval
                        if time_since_last >= self.arrow_key_state['seek_interval']:
                            should_navigate = True
                    # else: Still in the delay period, don't navigate (allows precise frame-by-frame)

            if should_navigate:
                self._perform_frame_seek(seek_direction)
                self.arrow_key_state['last_seek_time'] = current_time

    def _perform_frame_seek(self, delta_frames):
        """Arrow key navigation with rolling backward buffer"""
        if not self.app.processor or not self.app.processor.video_info:
            return

        # Skip if already seeking to avoid frame jump issues
        if self.app.processor.seek_in_progress:
            return

        new_frame = self.app.processor.current_frame_index + delta_frames
        total_frames = self.app.processor.total_frames
        new_frame = max(0, min(new_frame, total_frames - 1 if total_frames > 0 else 0))

        if new_frame == self.app.processor.current_frame_index:
            return  # No change needed

        # Only use rolling buffer when NOT tracking/processing
        if not self.app.processor.is_processing and not (self.app.tracker and self.app.tracker.tracking_active):
            if delta_frames > 0:
                # Forward: sequential read + add to backward buffer
                frame = self.app.processor.arrow_nav_forward(new_frame)
                if frame is not None:
                    self.app.processor.current_frame = frame
                    # Add to rolling backward buffer for future backward navigation
                    self.app.processor.add_frame_to_backward_buffer(new_frame, frame)
            else:
                # Backward: use rolling buffer (with async refill if needed)
                frame = self.app.processor.arrow_nav_backward(new_frame)
                if frame is not None:
                    self.app.processor.current_frame = frame
        else:
            # During tracking/processing: use standard cache-based seek
            frame_from_cache = None
            with self.app.processor.frame_cache_lock:
                if new_frame in self.app.processor.frame_cache:
                    frame_from_cache = self.app.processor.frame_cache[new_frame]
                    self.app.processor.frame_cache.move_to_end(new_frame)

            if frame_from_cache is not None:
                self.app.processor.current_frame_index = new_frame
                self.app.processor.current_frame = frame_from_cache
            else:
                self.app.processor.current_frame_index = new_frame
                self.app.processor.seek_video(new_frame)

        # Update UI
        self.app.app_state_ui.force_timeline_pan_to_current_frame = True
        if self.app.project_manager:
            self.app.project_manager.project_dirty = True
        self.app.energy_saver.reset_activity_timer()

    # Removed complex predictive caching - it was blocking the UI
    # Keep navigation simple: cache check first, then single frame fetch if needed

    def _handle_set_chapter_start_shortcut(self):
        """Handle keyboard shortcut for setting chapter start (I key)"""
        current_frame = self._get_current_frame_for_chapter()
        if hasattr(self, 'video_navigation_ui') and self.video_navigation_ui:
            # If chapter dialog is open, update it
            if self.video_navigation_ui.show_create_chapter_dialog or self.video_navigation_ui.show_edit_chapter_dialog:
                self.video_navigation_ui.chapter_edit_data["start_frame_str"] = str(current_frame)
                self.app.logger.info(f"Chapter start set to frame {current_frame}", extra={'status_message': True})
            else:
                # Store for future chapter creation
                self._stored_chapter_start_frame = current_frame
                self.app.logger.info(f"Chapter start marked at frame {current_frame} (Press O to set end, then Shift+C to create)", extra={'status_message': True})
    
    def _handle_set_chapter_end_shortcut(self):
        """Handle keyboard shortcut for setting chapter end (O key)"""
        current_frame = self._get_current_frame_for_chapter()
        if hasattr(self, 'video_navigation_ui') and self.video_navigation_ui:
            # If chapter dialog is open, update it
            if self.video_navigation_ui.show_create_chapter_dialog or self.video_navigation_ui.show_edit_chapter_dialog:
                self.video_navigation_ui.chapter_edit_data["end_frame_str"] = str(current_frame)
                self.app.logger.info(f"Chapter end set to frame {current_frame}", extra={'status_message': True})
            else:
                # Store for future chapter creation and auto-create if start is set
                self._stored_chapter_end_frame = current_frame
                if hasattr(self, '_stored_chapter_start_frame'):
                    self._auto_create_chapter_from_stored_frames()
                else:
                    self.app.logger.info(f"Chapter end marked at frame {current_frame} (Press I to set start, then Shift+C to create)", extra={'status_message': True})

    def _handle_add_point_at_value(self, value: int):
        """Add a point at the current video playhead position with the specified value (0-100).

        The point is added to the active timeline (the one with the green border).
        Uses the timeline's _add_point() method which handles snapping, undo, and cache invalidation.
        """
        if not self.app.processor or not self.app.processor.video_info:
            return

        # Get current video time
        current_frame = self.app.processor.current_frame_index
        fps = self.app.processor.fps
        if fps <= 0:
            return

        current_time_ms = int((current_frame / fps) * 1000)

        # Get the active timeline and add the point
        app_state = self.app.app_state_ui
        timeline_num = getattr(app_state, 'active_timeline_num', 1)

        # Get timeline from GUI instance (timelines are stored as timeline_editor1/2 in AppGUI)
        if timeline_num == 1:
            timeline = self.timeline_editor1
        elif timeline_num == 2:
            timeline = self.timeline_editor2
        else:
            timeline = None

        if timeline:
            timeline._add_point(current_time_ms, value)
            self.app.logger.info(f"Added point: {value}% at {current_time_ms}ms (Timeline {timeline_num})", extra={'status_message': True})
        else:
            self.app.logger.warning(f"Timeline {timeline_num} not found")

    def _get_current_frame_for_chapter(self) -> int:
        """Get current video frame for chapter operations"""
        if self.app.processor and hasattr(self.app.processor, 'current_frame_index'):
            return max(0, self.app.processor.current_frame_index)
        return 0
    
    def _auto_create_chapter_from_stored_frames(self):
        """Automatically create chapter when both start and end frames are marked"""
        if not (hasattr(self, '_stored_chapter_start_frame') and hasattr(self, '_stored_chapter_end_frame')):
            return
        
        start_frame = self._stored_chapter_start_frame
        end_frame = self._stored_chapter_end_frame
        
        # Ensure start is before end
        if start_frame > end_frame:
            start_frame, end_frame = end_frame, start_frame
        
        # Create chapter data
        if hasattr(self, 'video_navigation_ui') and self.video_navigation_ui and self.app.funscript_processor:
            default_pos_key = self.video_navigation_ui.position_short_name_keys[0] if self.video_navigation_ui.position_short_name_keys else "N/A"
            chapter_data = {
                "start_frame_str": str(start_frame),
                "end_frame_str": str(end_frame),
                "segment_type": "SexAct",
                "position_short_name_key": default_pos_key,
                "source": "keyboard_shortcut"
            }
            
            self.app.funscript_processor.create_new_chapter_from_data(chapter_data)
            self.app.logger.info(f"Chapter created: frames {start_frame} to {end_frame}", extra={'status_message': True})
            
            # Clear stored frames
            if hasattr(self, '_stored_chapter_start_frame'):
                delattr(self, '_stored_chapter_start_frame')
            if hasattr(self, '_stored_chapter_end_frame'):
                delattr(self, '_stored_chapter_end_frame')

    # --- New Shortcut Handlers ---

    def _handle_save_project_shortcut(self):
        """Handle keyboard shortcut for saving project (CMD+S / CTRL+S)"""
        self.app.project_manager.save_project_dialog()

    def _handle_open_project_shortcut(self):
        """Handle keyboard shortcut for opening project (CMD+O / CTRL+O)"""
        self.app.project_manager.open_project_dialog()

    def _handle_jump_to_start_shortcut(self):
        """Handle keyboard shortcut for jumping to video start (HOME)"""
        if self.app.processor:
            self.app.processor.seek_video(0)
            self.app.app_state_ui.force_timeline_pan_to_current_frame = True
            if self.app.project_manager:
                self.app.project_manager.project_dirty = True
            self.app.energy_saver.reset_activity_timer()

    def _handle_jump_to_end_shortcut(self):
        """Handle keyboard shortcut for jumping to video end (END)"""
        if self.app.processor:
            last_frame = max(0, self.app.processor.total_frames - 1) if self.app.processor.total_frames > 0 else 0
            self.app.processor.seek_video(last_frame)
            self.app.app_state_ui.force_timeline_pan_to_current_frame = True
            if self.app.project_manager:
                self.app.project_manager.project_dirty = True
            self.app.energy_saver.reset_activity_timer()

    def _handle_zoom_in_timeline_shortcut(self):
        """Handle keyboard shortcut for zooming in timeline (CMD+= / CTRL+=)"""
        # Apply zoom in with scale factor (0.85 = zoom in)
        app_state = self.app.app_state_ui
        scale_factor = 0.85

        # Zoom around current time (center of view)
        effective_total_duration_s, _, _ = self.app.get_effective_video_duration_params()
        effective_total_duration_ms = effective_total_duration_s * 1000.0

        # Get current center time
        if self.timeline_editor1:
            # Use timeline 1's center marker position
            center_time_ms = app_state.timeline_pan_offset_ms
        else:
            center_time_ms = 0.0

        # Apply zoom
        min_ms_per_px, max_ms_per_px = 0.01, 2000.0
        old_zoom = app_state.timeline_zoom_factor_ms_per_px
        app_state.timeline_zoom_factor_ms_per_px = max(
            min_ms_per_px,
            min(app_state.timeline_zoom_factor_ms_per_px * scale_factor, max_ms_per_px),
        )

        # Adjust pan offset to keep center time roughly in place
        if old_zoom != app_state.timeline_zoom_factor_ms_per_px:
            self.app.energy_saver.reset_activity_timer()

    def _handle_zoom_out_timeline_shortcut(self):
        """Handle keyboard shortcut for zooming out timeline (CMD+- / CTRL+-)"""
        # Apply zoom out with scale factor (1.15 = zoom out)
        app_state = self.app.app_state_ui
        scale_factor = 1.15

        # Zoom around current time (center of view)
        effective_total_duration_s, _, _ = self.app.get_effective_video_duration_params()
        effective_total_duration_ms = effective_total_duration_s * 1000.0

        # Get current center time
        if self.timeline_editor1:
            # Use timeline 1's center marker position
            center_time_ms = app_state.timeline_pan_offset_ms
        else:
            center_time_ms = 0.0

        # Apply zoom
        min_ms_per_px, max_ms_per_px = 0.01, 2000.0
        old_zoom = app_state.timeline_zoom_factor_ms_per_px
        app_state.timeline_zoom_factor_ms_per_px = max(
            min_ms_per_px,
            min(app_state.timeline_zoom_factor_ms_per_px * scale_factor, max_ms_per_px),
        )

        # Adjust pan offset to keep center time roughly in place
        if old_zoom != app_state.timeline_zoom_factor_ms_per_px:
            self.app.energy_saver.reset_activity_timer()

    def _handle_toggle_video_display_shortcut(self):
        """Handle keyboard shortcut for toggling video display (V)"""
        app_state = self.app.app_state_ui
        # Only allow toggle in floating mode - in fixed mode video display is always shown
        if app_state.ui_layout_mode == "floating":
            app_state.show_video_display_window = not app_state.show_video_display_window
            if self.app.project_manager:
                self.app.project_manager.project_dirty = True
            status = "shown" if app_state.show_video_display_window else "hidden"
            self.app.logger.info(f"Video display {status}", extra={'status_message': True})
        else:
            self.app.logger.info("Video display toggle only available in floating mode", extra={'status_message': True})
        self.app.energy_saver.reset_activity_timer()

    def _handle_toggle_timeline2_shortcut(self):
        """Handle keyboard shortcut for toggling timeline 2 (T)"""
        app_state = self.app.app_state_ui
        app_state.show_funscript_interactive_timeline2 = not app_state.show_funscript_interactive_timeline2
        if self.app.project_manager:
            self.app.project_manager.project_dirty = True
        status = "shown" if app_state.show_funscript_interactive_timeline2 else "hidden"
        self.app.logger.info(f"Timeline 2 {status}", extra={'status_message': True})
        self.app.energy_saver.reset_activity_timer()

    def _handle_toggle_gauge_window_shortcut(self):
        """Handle keyboard shortcut for toggling gauge window (G)"""
        app_state = self.app.app_state_ui
        # Toggle gauge window for timeline 1
        if not hasattr(app_state, 'show_gauge_window_timeline1'):
            app_state.show_gauge_window_timeline1 = False
        app_state.show_gauge_window_timeline1 = not app_state.show_gauge_window_timeline1
        if self.app.project_manager:
            self.app.project_manager.project_dirty = True
        status = "shown" if app_state.show_gauge_window_timeline1 else "hidden"
        self.app.logger.info(f"Gauge window {status}", extra={'status_message': True})
        self.app.energy_saver.reset_activity_timer()

    def _handle_toggle_3d_simulator_shortcut(self):
        """Handle keyboard shortcut for toggling 3D simulator (S)"""
        app_state = self.app.app_state_ui
        app_state.show_simulator_3d = not app_state.show_simulator_3d
        if self.app.project_manager:
            self.app.project_manager.project_dirty = True
        status = "shown" if app_state.show_simulator_3d else "hidden"
        self.app.logger.info(f"3D Simulator {status}", extra={'status_message': True})
        self.app.energy_saver.reset_activity_timer()

    def _handle_toggle_movement_bar_shortcut(self):
        """Handle keyboard shortcut for toggling movement bar (M)"""
        app_state = self.app.app_state_ui
        app_state.show_lr_dial_graph = not app_state.show_lr_dial_graph
        if self.app.project_manager:
            self.app.project_manager.project_dirty = True
        status = "shown" if app_state.show_lr_dial_graph else "hidden"
        self.app.logger.info(f"Movement Bar {status}", extra={'status_message': True})
        self.app.energy_saver.reset_activity_timer()

    def _handle_toggle_chapter_list_shortcut(self):
        """Handle keyboard shortcut for toggling chapter list (L)"""
        app_state = self.app.app_state_ui
        if not hasattr(app_state, 'show_chapter_list_window'):
            app_state.show_chapter_list_window = False
        app_state.show_chapter_list_window = not app_state.show_chapter_list_window
        if self.app.project_manager:
            self.app.project_manager.project_dirty = True
        status = "shown" if app_state.show_chapter_list_window else "hidden"
        self.app.logger.info(f"Chapter List {status}", extra={'status_message': True})
        self.app.energy_saver.reset_activity_timer()

    def _handle_toggle_heatmap_shortcut(self):
        """Handle keyboard shortcut for toggling heatmap (H)"""
        app_state = self.app.app_state_ui
        app_state.show_heatmap = not app_state.show_heatmap
        if self.app.project_manager:
            self.app.project_manager.project_dirty = True
        status = "shown" if app_state.show_heatmap else "hidden"
        self.app.logger.info(f"Heatmap {status}", extra={'status_message': True})
        self.app.energy_saver.reset_activity_timer()

    def _handle_toggle_funscript_preview_shortcut(self):
        """Handle keyboard shortcut for toggling funscript preview bar (P)"""
        app_state = self.app.app_state_ui
        app_state.show_funscript_timeline = not app_state.show_funscript_timeline
        if self.app.project_manager:
            self.app.project_manager.project_dirty = True
        status = "shown" if app_state.show_funscript_timeline else "hidden"
        self.app.logger.info(f"Funscript Preview {status}", extra={'status_message': True})
        self.app.energy_saver.reset_activity_timer()

    def _handle_toggle_video_feed_shortcut(self):
        """Handle keyboard shortcut for toggling video feed overlay (F)"""
        app_state = self.app.app_state_ui
        app_state.show_video_feed = not app_state.show_video_feed
        self.app.app_settings.set("show_video_feed", app_state.show_video_feed)
        if self.app.project_manager:
            self.app.project_manager.project_dirty = True
        status = "shown" if app_state.show_video_feed else "hidden"
        self.app.logger.info(f"Video Feed {status}", extra={'status_message': True})
        self.app.energy_saver.reset_activity_timer()

    def _handle_toggle_waveform_shortcut(self):
        """Handle keyboard shortcut for toggling audio waveform (W)"""
        app_state = self.app.app_state_ui
        app_state.show_audio_waveform = not app_state.show_audio_waveform
        if self.app.project_manager:
            self.app.project_manager.project_dirty = True
        status = "shown" if app_state.show_audio_waveform else "hidden"
        self.app.logger.info(f"Audio Waveform {status}", extra={'status_message': True})
        self.app.energy_saver.reset_activity_timer()

    def _handle_reset_timeline_view_shortcut(self):
        """Handle keyboard shortcut for resetting timeline zoom/pan (R)"""
        app_state = self.app.app_state_ui

        # Reset zoom to default (20.0 ms per pixel is a good default)
        app_state.timeline_zoom_factor_ms_per_px = 20.0

        # Reset pan to start
        app_state.timeline_pan_offset_ms = 0.0

        # Force timeline to pan to current frame
        app_state.force_timeline_pan_to_current_frame = True

        self.app.logger.info("Timeline view reset to default", extra={'status_message': True})
        self.app.energy_saver.reset_activity_timer()

    def _handle_energy_saver_interaction_detection(self):
        io = imgui.get_io()
        interaction_detected_this_frame = False
        current_mouse_pos = io.mouse_pos
        if current_mouse_pos[0] != self.last_mouse_pos_for_energy_saver[0] or current_mouse_pos[1] != self.last_mouse_pos_for_energy_saver[1]:
            interaction_detected_this_frame = True
            self.last_mouse_pos_for_energy_saver = current_mouse_pos

        # REFACTORED for readability and maintainability
        buttons = (0, 1, 2)
        if (any(imgui.is_mouse_clicked(b) or imgui.is_mouse_double_clicked(b) for b in buttons)
            or io.mouse_wheel != 0.0
            or io.want_text_input
            or imgui.is_mouse_dragging(0)
            or imgui.is_any_item_active()
            or imgui.is_any_item_focused()):
                interaction_detected_this_frame = True
        if hasattr(io, 'keys_down'):
            for i in range(len(io.keys_down)):
                if imgui.is_key_pressed(i): interaction_detected_this_frame = True; break
        if interaction_detected_this_frame:
            self.app.energy_saver.reset_activity_timer()

    def _render_batch_confirmation_dialog(self):
        app = self.app
        if not app.show_batch_confirmation_dialog:
            return

        colors = self.colors
        imgui.open_popup("Batch Processing Setup")
        main_viewport = imgui.get_main_viewport()
        imgui.set_next_window_size(main_viewport.size[0] * 0.7, main_viewport.size[1] * 0.8, condition=imgui.APPEARING)
        popup_pos = (main_viewport.pos[0] + main_viewport.size[0] * 0.5,
                     main_viewport.pos[1] + main_viewport.size[1] * 0.5)
        imgui.set_next_window_position(popup_pos[0], popup_pos[1], pivot_x=0.5, pivot_y=0.5, condition=imgui.APPEARING)

        if imgui.begin_popup_modal("Batch Processing Setup", True)[0]:
            imgui.text(f"Found {len(self.batch_videos_data)} videos for batch processing.")
            imgui.separator()

            imgui.text("Overwrite Strategy:")
            imgui.same_line()
            if imgui.radio_button("Skip existing FunGen scripts", self.batch_overwrite_mode_ui == 0): self.batch_overwrite_mode_ui = 0
            imgui.same_line()
            if imgui.radio_button("Skip if ANY script exists", self.batch_overwrite_mode_ui == 1): self.batch_overwrite_mode_ui = 1
            imgui.same_line()
            if imgui.radio_button("Overwrite all existing scripts", self.batch_overwrite_mode_ui == 2): self.batch_overwrite_mode_ui = 2

            if self.batch_overwrite_mode_ui != self.last_overwrite_mode_ui:
                for video in self.batch_videos_data:
                    status = video["funscript_status"]
                    if self.batch_overwrite_mode_ui == 0: video["selected"] = status != 'fungen'
                    elif self.batch_overwrite_mode_ui == 1: video["selected"] = status is None
                    elif self.batch_overwrite_mode_ui == 2: video["selected"] = True
                self.last_overwrite_mode_ui = self.batch_overwrite_mode_ui

            imgui.separator()

            if imgui.begin_child("VideoList", height=-120):
                table_flags = imgui.TABLE_BORDERS | imgui.TABLE_SIZING_STRETCH_PROP | imgui.TABLE_SCROLL_Y
                if imgui.begin_table("BatchVideosTable", 4, flags=table_flags):
                    imgui.table_setup_column("Process", init_width_or_weight=0.5)
                    imgui.table_setup_column("Video File", init_width_or_weight=4.0)
                    imgui.table_setup_column("Detected", init_width_or_weight=1.3)
                    imgui.table_setup_column("Override", init_width_or_weight=1.5)

                    imgui.table_headers_row()

                    video_format_options = ["Auto (Heuristic)", "2D", "VR (he_sbs)", "VR (he_tb)", "VR (fisheye_sbs)", "VR (fisheye_tb)"]

                    for i, video_data in enumerate(self.batch_videos_data):
                        imgui.table_next_row()
                        imgui.table_set_column_index(0); imgui.push_id(f"sel_{i}")
                        _, video_data["selected"] = imgui.checkbox("##select", video_data["selected"])
                        imgui.pop_id()

                        imgui.table_set_column_index(1)
                        status = video_data["funscript_status"]
                        if status == 'fungen': imgui.text_colored(os.path.basename(video_data["path"]), *colors.VIDEO_STATUS_FUNGEN)
                        elif status == 'other': imgui.text_colored(os.path.basename(video_data["path"]), *colors.VIDEO_STATUS_OTHER)
                        else: imgui.text(os.path.basename(video_data["path"]))

                        if imgui.is_item_hovered():
                            if status == 'fungen':
                                imgui.set_tooltip("Funscript created by this version of FunGen")
                            elif status == 'other':
                                imgui.set_tooltip("Funscript exists (unknown or older version)")
                            else:
                                imgui.set_tooltip("No Funscript exists for this video")

                        imgui.table_set_column_index(2); imgui.text(video_data["detected_format"])

                        imgui.table_set_column_index(3); imgui.push_id(f"ovr_{i}"); imgui.set_next_item_width(-1)
                        _, video_data["override_format_idx"] = imgui.combo("##override", video_data["override_format_idx"], video_format_options)
                        imgui.pop_id()

                    imgui.end_table()
                imgui.end_child()

            imgui.separator()
            imgui.text("Processing Method:")
            
            # Get available batch-compatible trackers dynamically
            from application.gui_components.dynamic_tracker_ui import get_dynamic_tracker_ui
            from config.tracker_discovery import TrackerCategory
            
            tracker_ui = get_dynamic_tracker_ui()
            discovery = tracker_ui.discovery
            
            # Get live (non-intervention) and offline trackers
            batch_compatible_trackers = []
            tracker_internal_names = []
            
            # Add offline trackers
            offline_trackers = discovery.get_trackers_by_category(TrackerCategory.OFFLINE)
            for tracker in offline_trackers:
                if tracker.supports_batch:
                    # Add prefix based on folder name
                    if tracker.folder_name and tracker.folder_name.lower() == "experimental":
                        display_name = f"Experimental: {tracker.display_name}"
                    else:
                        display_name = f"Offline: {tracker.display_name}"
                    batch_compatible_trackers.append(display_name)
                    tracker_internal_names.append(tracker.internal_name)
            
            # Add live trackers (non-intervention only)
            live_trackers = discovery.get_trackers_by_category(TrackerCategory.LIVE)
            for tracker in live_trackers:
                if tracker.supports_batch and not tracker.requires_intervention:
                    # Add prefix based on folder name
                    if tracker.folder_name and tracker.folder_name.lower() == "experimental":
                        display_name = f"Experimental: {tracker.display_name}"
                    else:
                        display_name = f"Live: {tracker.display_name}"
                    batch_compatible_trackers.append(display_name)
                    tracker_internal_names.append(tracker.internal_name)
            
            # Create dropdown
            imgui.set_next_item_width(300)
            changed, self.selected_batch_method_idx_ui = imgui.combo(
                "##batch_tracker", 
                self.selected_batch_method_idx_ui,
                batch_compatible_trackers
            )
            
            # Store the selected tracker's internal name for later use
            if 0 <= self.selected_batch_method_idx_ui < len(tracker_internal_names):
                self.selected_batch_tracker_name = tracker_internal_names[self.selected_batch_method_idx_ui]
            else:
                self.selected_batch_tracker_name = None

            imgui.text("Output Options:")
            _, self.batch_apply_ultimate_autotune_ui = imgui.checkbox("Apply Ultimate Autotune", self.batch_apply_ultimate_autotune_ui)
            imgui.same_line()
            _, self.batch_copy_funscript_to_video_location_ui = imgui.checkbox("Save copy next to video", self.batch_copy_funscript_to_video_location_ui)
            imgui.same_line()
            
            # Check if selected tracker supports roll file generation (3-stage trackers)
            has_3_stages = False
            if hasattr(self, 'selected_batch_tracker_name') and self.selected_batch_tracker_name:
                tracker_info = discovery.get_tracker_info(self.selected_batch_tracker_name)
                if tracker_info and tracker_info.properties:
                    has_3_stages = tracker_info.properties.get("num_stages", 0) >= 3
            
            if not has_3_stages:
                imgui.internal.push_item_flag(imgui.internal.ITEM_DISABLED, True); imgui.push_style_var(imgui.STYLE_ALPHA, 0.5)
            _, self.batch_generate_roll_file_ui = imgui.checkbox("Generate .roll file", self.batch_generate_roll_file_ui if has_3_stages else False)
            if not has_3_stages:
                imgui.pop_style_var(); imgui.internal.pop_item_flag()

            imgui.separator()
            if imgui.button("Start Batch", width=120):
                app._initiate_batch_processing_from_confirmation()
                imgui.close_current_popup()
            imgui.same_line()
            if imgui.button("Cancel", width=120):
                app._cancel_batch_processing_from_confirmation()
                imgui.close_current_popup()

            imgui.end_popup()

    def render_gui(self):
        self.component_render_times.clear()

        # Energy detection can be done before new_frame
        self._time_render("EnergyDetection", self._handle_energy_saver_interaction_detection)

        self._time_render("StageProcessorEvents", self.app.stage_processor.process_gui_events)

        # --- Process preview results queue every frame ---
        self._process_preview_results()

        imgui.new_frame()

        # IMPORTANT: Global shortcuts must be called AFTER new_frame() because
        # imgui.is_key_pressed() relies on KeysDownDuration which is updated by new_frame().
        # Previously shortcuts were called before new_frame, causing is_key_pressed to always return False.
        self._time_render("GlobalShortcuts", self._handle_global_shortcuts)

        if self.app.shortcut_manager.is_recording_shortcut_for:
            self._time_render("ShortcutRecordingInput", self.app.shortcut_manager.handle_shortcut_recording_input)
            self.app.energy_saver.reset_activity_timer()

        main_viewport = imgui.get_main_viewport()
        self.window_width, self.window_height = main_viewport.size
        app_state = self.app.app_state_ui
        app_state.window_width = int(self.window_width)
        app_state.window_height = int(self.window_height)

        self._time_render("MainMenu", self.main_menu.render)

        # Render toolbar
        self._time_render("Toolbar", self.toolbar_ui.render)

        font_scale = self.app.app_settings.get("global_font_scale", 1.0)
        imgui.get_io().font_global_scale = font_scale

        if hasattr(app_state, 'main_menu_bar_height_from_menu_class'):
            self.main_menu_bar_height = app_state.main_menu_bar_height_from_menu_class
        else:
            self.main_menu_bar_height = imgui.get_frame_height_with_spacing() if self.main_menu else 0

        # Account for toolbar height (includes section labels) - only if shown
        if not hasattr(app_state, 'show_toolbar'):
            app_state.show_toolbar = True
        toolbar_height = self.toolbar_ui.get_toolbar_height() if app_state.show_toolbar else 0

        if not app_state.gauge_pos_initialized and self.main_menu_bar_height > 0:
            app_state.initialize_gauge_default_y(self.main_menu_bar_height + toolbar_height)

        app_state.update_current_script_display_values()

        if app_state.ui_layout_mode == 'fixed':
            panel_y_start = self.main_menu_bar_height + toolbar_height
            timeline1_render_h = app_state.timeline_base_height if app_state.show_funscript_interactive_timeline else 0
            timeline2_render_h = app_state.timeline_base_height if app_state.show_funscript_interactive_timeline2 else 0
            interactive_timelines_total_height = timeline1_render_h + timeline2_render_h
            available_height_for_main_panels = max(100, self.window_height - panel_y_start - interactive_timelines_total_height)
            app_state.fixed_layout_geometry = {}
            is_full_width_nav = getattr(app_state, 'full_width_nav', False)
            control_panel_w = 450 * font_scale
            graphs_panel_w = 450 * font_scale
            video_nav_bar_h = 150

            if is_full_width_nav:
                top_panels_h = max(50, available_height_for_main_panels - video_nav_bar_h)
                nav_y_start = panel_y_start + top_panels_h
                # In fixed mode, video display is always shown
                if True:
                    video_panel_w = self.window_width - control_panel_w - graphs_panel_w
                    if video_panel_w < 100:
                        video_panel_w = 100
                        graphs_panel_w = max(100, self.window_width - control_panel_w - video_panel_w)
                    video_area_x_start = control_panel_w
                    graphs_area_x_start = control_panel_w + video_panel_w
                    app_state.fixed_layout_geometry['ControlPanel'] = {'pos': (0, panel_y_start), 'size': (control_panel_w, top_panels_h)}
                    imgui.set_next_window_position(0, panel_y_start)
                    imgui.set_next_window_size(control_panel_w, top_panels_h)
                    self._time_render("ControlPanelUI", self.control_panel_ui.render)
                    app_state.fixed_layout_geometry['VideoDisplay'] = {'pos': (video_area_x_start, panel_y_start), 'size': (video_panel_w, top_panels_h)}
                    imgui.set_next_window_position(video_area_x_start, panel_y_start)
                    imgui.set_next_window_size(video_panel_w, top_panels_h)
                    self._time_render("VideoDisplayUI", self.video_display_ui.render)
                    app_state.fixed_layout_geometry['InfoGraphs'] = {'pos': (graphs_area_x_start, panel_y_start), 'size': (graphs_panel_w, top_panels_h)}
                    imgui.set_next_window_position(graphs_area_x_start, panel_y_start)
                    imgui.set_next_window_size(graphs_panel_w, top_panels_h)
                    self._time_render("InfoGraphsUI", self.info_graphs_ui.render)
                else:
                    control_panel_w_no_vid = self.window_width / 2
                    graphs_panel_w_no_vid = self.window_width - control_panel_w_no_vid
                    graphs_area_x_start_no_vid = control_panel_w_no_vid
                    app_state.fixed_layout_geometry['ControlPanel'] = {'pos': (0, panel_y_start), 'size': (control_panel_w_no_vid, top_panels_h)}
                    imgui.set_next_window_position(0, panel_y_start)
                    imgui.set_next_window_size(control_panel_w_no_vid, top_panels_h)
                    self._time_render("ControlPanelUI", self.control_panel_ui.render)
                    app_state.fixed_layout_geometry['InfoGraphs'] = {'pos': (graphs_area_x_start_no_vid, panel_y_start), 'size': (graphs_panel_w_no_vid, top_panels_h)}
                    imgui.set_next_window_position(graphs_area_x_start_no_vid, panel_y_start)
                    imgui.set_next_window_size(graphs_panel_w_no_vid, top_panels_h)
                    self._time_render("InfoGraphsUI", self.info_graphs_ui.render)
                app_state.fixed_layout_geometry['VideoNavigation'] = {'pos': (0, nav_y_start), 'size': (self.window_width, video_nav_bar_h)}
                imgui.set_next_window_position(0, nav_y_start)
                imgui.set_next_window_size(self.window_width, video_nav_bar_h)
                self._time_render("VideoNavigationUI", self.video_navigation_ui.render, self.window_width)
            else:
                # In fixed mode, video display is always shown
                if True:
                    video_panel_w = self.window_width - control_panel_w - graphs_panel_w
                    if video_panel_w < 100:
                        video_panel_w = 100
                        graphs_panel_w = max(100, self.window_width - control_panel_w - video_panel_w)
                    video_render_h = max(50, available_height_for_main_panels - video_nav_bar_h)
                    video_area_x_start = control_panel_w
                    graphs_area_x_start = control_panel_w + video_panel_w
                    app_state.fixed_layout_geometry['ControlPanel'] = {'pos': (0, panel_y_start), 'size': (control_panel_w, available_height_for_main_panels)}
                    imgui.set_next_window_position(0, panel_y_start)
                    imgui.set_next_window_size(control_panel_w, available_height_for_main_panels)
                    self._time_render("ControlPanelUI", self.control_panel_ui.render)
                    app_state.fixed_layout_geometry['VideoDisplay'] = {'pos': (video_area_x_start, panel_y_start), 'size': (video_panel_w, video_render_h)}
                    imgui.set_next_window_position(video_area_x_start, panel_y_start)
                    imgui.set_next_window_size(video_panel_w, video_render_h)
                    self._time_render("VideoDisplayUI", self.video_display_ui.render)
                    app_state.fixed_layout_geometry['VideoNavigation'] = {
                        'pos': (video_area_x_start, panel_y_start + video_render_h),
                        'size': (video_panel_w, video_nav_bar_h)}
                    imgui.set_next_window_position(video_area_x_start, panel_y_start + video_render_h)
                    imgui.set_next_window_size(video_panel_w, video_nav_bar_h)
                    self._time_render("VideoNavigationUI", self.video_navigation_ui.render, video_panel_w)
                    app_state.fixed_layout_geometry['InfoGraphs'] = {'pos': (graphs_area_x_start, panel_y_start), 'size': (graphs_panel_w, available_height_for_main_panels)}
                    imgui.set_next_window_position(graphs_area_x_start, panel_y_start)
                    imgui.set_next_window_size(graphs_panel_w, available_height_for_main_panels)
                    self._time_render("InfoGraphsUI", self.info_graphs_ui.render)
                else:
                    control_panel_w_no_vid = self.window_width / 2
                    graphs_panel_w_no_vid = self.window_width - control_panel_w_no_vid
                    graphs_area_x_start_no_vid = control_panel_w_no_vid
                    app_state.fixed_layout_geometry['ControlPanel'] = {'pos': (0, panel_y_start), 'size': (control_panel_w_no_vid, available_height_for_main_panels)}
                    imgui.set_next_window_position(0, panel_y_start)
                    imgui.set_next_window_size(control_panel_w_no_vid, available_height_for_main_panels)
                    self._time_render("ControlPanelUI", self.control_panel_ui.render)
                    app_state.fixed_layout_geometry['InfoGraphs'] = {'pos': (graphs_area_x_start_no_vid, panel_y_start), 'size': (graphs_panel_w_no_vid, available_height_for_main_panels)}
                    imgui.set_next_window_position(graphs_area_x_start_no_vid, panel_y_start)
                    imgui.set_next_window_size(graphs_panel_w_no_vid, available_height_for_main_panels)
                    self._time_render("InfoGraphsUI", self.info_graphs_ui.render)

            timeline_current_y_start = panel_y_start + available_height_for_main_panels
            if app_state.show_funscript_interactive_timeline:
                app_state.fixed_layout_geometry['Timeline1'] = {'pos': (0, timeline_current_y_start), 'size': (self.window_width, timeline1_render_h)}
                self._time_render("TimelineEditor1", self.timeline_editor1.render, timeline_current_y_start, timeline1_render_h, view_mode=app_state.ui_view_mode)
                timeline_current_y_start += timeline1_render_h
            if app_state.show_funscript_interactive_timeline2:
                app_state.fixed_layout_geometry['Timeline2'] = {'pos': (0, timeline_current_y_start), 'size': (self.window_width, timeline2_render_h)}
                self._time_render("TimelineEditor2", self.timeline_editor2.render, timeline_current_y_start, timeline2_render_h, view_mode=app_state.ui_view_mode)
        else:
            if app_state.just_switched_to_floating:
                if 'ControlPanel' in app_state.fixed_layout_geometry:
                    geom = app_state.fixed_layout_geometry['ControlPanel']
                    imgui.set_next_window_position(geom['pos'][0], geom['pos'][1], condition=imgui.APPEARING)
                    imgui.set_next_window_size(geom['size'][0], geom['size'][1], condition=imgui.APPEARING)
                if 'VideoDisplay' in app_state.fixed_layout_geometry:
                    geom = app_state.fixed_layout_geometry['VideoDisplay']
                    imgui.set_next_window_position(geom['pos'][0], geom['pos'][1], condition=imgui.APPEARING)
                    imgui.set_next_window_size(geom['size'][0], geom['size'][1], condition=imgui.APPEARING)

            self._time_render("ControlPanelUI", self.control_panel_ui.render)
            self._time_render("InfoGraphsUI", self.info_graphs_ui.render)
            self._time_render("VideoDisplayUI", self.video_display_ui.render)
            self._time_render("VideoNavigationUI", self.video_navigation_ui.render)
            self._time_render("TimelineEditor1", self.timeline_editor1.render)
            self._time_render("TimelineEditor2", self.timeline_editor2.render)
            if app_state.just_switched_to_floating:
                app_state.just_switched_to_floating = False

        if hasattr(app_state, 'show_chapter_list_window') and app_state.show_chapter_list_window:
            self._time_render("ChapterListWindow", self.chapter_list_window_ui.render)
        if hasattr(app_state, 'show_chapter_type_manager') and app_state.show_chapter_type_manager:
            self._time_render("ChapterTypeManager", self.chapter_type_manager_ui.render)
        self._time_render("Popups", self._render_all_popups)
        self._time_render("EnergySaverIndicator", self._render_energy_saver_indicator)

        # TODO: Move this to a separate class/error management module  
        self._time_render("ErrorPopup", self._render_error_popup)

        # Render TensorRT Compiler Window if open
        if hasattr(self.app, 'tensorrt_compiler_window') and self.app.tensorrt_compiler_window:
            self._time_render("TensorRTCompiler", self.app.tensorrt_compiler_window.render)

        # --- Render Generated File Manager window ---
        if self.app.app_state_ui.show_generated_file_manager:
            self._time_render("GeneratedFileManager", self.generated_file_manager_ui.render)

        # --- Render Autotuner Window ---
        self._time_render("AutotunerWindow", self.autotuner_window_ui.render)

        # --- Render AI Models Dialog ---
        if hasattr(app_state, 'show_ai_models_dialog') and app_state.show_ai_models_dialog:
            self._time_render("AIModelsDialog", self._render_ai_models_dialog)

        self.perf_frame_count += 1
        if time.time() - self.last_perf_log_time > self.perf_log_interval:
            self._log_performance()
        
        # Continuously update frontend queue with current data
        self._update_frontend_perf_queue()

        # Track final rendering operations
        self._time_render("ImGuiRender", imgui.render)
        if self.impl:
            # Only measure OpenGL render time if it's likely to be significant
            # Skip timing for very simple frames to reduce overhead
            draw_data = imgui.get_draw_data()
            if draw_data.total_vtx_count > 100 or draw_data.cmd_lists_count > 5:
                self._time_render("OpenGLRender", self.impl.render, draw_data)
            else:
                # Simple frame - render without timing overhead
                self.impl.render(draw_data)
                self.component_render_times["OpenGLRender"] = 0.0

    def _update_frontend_perf_queue(self):
        """
        Updates the frontend performance queue with the current accumulated times and frame count.
        Only updates if there is valid data to prevent empty entries.
        """
        # Only update queue if we have valid data
        if self.perf_accumulated_times and self.perf_frame_count > 0:
            current_perf_data = {
                'accumulated_times': self.perf_accumulated_times.copy(),
                'frame_count': self.perf_frame_count,
                'timestamp': time.time()
            }
            self._frontend_perf_queue.append(current_perf_data)

    def _render_ai_models_dialog(self):
        """Render AI Models configuration dialog."""
        app = self.app
        app_state = app.app_state_ui

        window_flags = imgui.WINDOW_NO_COLLAPSE
        main_viewport = imgui.get_main_viewport()
        center_x = main_viewport.pos[0] + main_viewport.size[0] * 0.5
        center_y = main_viewport.pos[1] + main_viewport.size[1] * 0.5
        imgui.set_next_window_position(center_x, center_y, imgui.ONCE, 0.5, 0.5)
        imgui.set_next_window_size(700, 400, imgui.ONCE)

        is_open, app_state.show_ai_models_dialog = imgui.begin(
            "AI Models Configuration##AIModelsDialog",
            closable=True,
            flags=window_flags
        )

        if is_open:
            imgui.text("Configure AI Model Paths and Inference Settings")
            imgui.separator()
            imgui.spacing()

            # Use the same rendering as control panel
            if hasattr(self, 'control_panel_ui') and self.control_panel_ui:
                self.control_panel_ui._render_ai_model_settings()

            imgui.spacing()
            imgui.separator()
            imgui.spacing()

            # Close button
            if imgui.button("Close", width=-1):
                app_state.show_ai_models_dialog = False

        imgui.end()

    def _render_status_message(self, app_state):
        if app_state.status_message and time.time() < app_state.status_message_time:
            imgui.set_next_window_position(self.window_width - 310, self.window_height - 40)
            imgui.begin("StatusMessage", flags=(
                imgui.WINDOW_NO_DECORATION |
                imgui.WINDOW_NO_MOVE |
                imgui.WINDOW_ALWAYS_AUTO_RESIZE |
                imgui.WINDOW_NO_INPUTS |
                imgui.WINDOW_NO_FOCUS_ON_APPEARING |
                imgui.WINDOW_NO_NAV))
            imgui.text(app_state.status_message)
            imgui.end()
        elif app_state.status_message:
            app_state.status_message = ""

    def _render_error_popup(self):
        """Render error popup with early return to avoid expensive operations when not needed."""
        # Early return if no error popup is active - avoids expensive ImGui operations
        if not self.error_popup_active and not imgui.is_popup_open("ErrorPopup"):
            return
            
        if self.error_popup_active:
            imgui.open_popup("ErrorPopup")
            
        # Center the popup and set a normal size (compatibility for imgui versions)
        if hasattr(imgui, 'get_main_viewport'):
            main_viewport = imgui.get_main_viewport()
            popup_pos = (main_viewport.pos[0] + main_viewport.size[0] * 0.5,
                         main_viewport.pos[1] + main_viewport.size[1] * 0.5)
            imgui.set_next_window_position(popup_pos[0], popup_pos[1], pivot_x=0.5, pivot_y=0.5)
        else:
            # Fallback: center on window size if viewport not available
            popup_pos = (self.window_width * 0.5, self.window_height * 0.5)
            imgui.set_next_window_position(popup_pos[0], popup_pos[1], pivot_x=0.5, pivot_y=0.5)
        popup_width = 600
        imgui.set_next_window_size(popup_width, 0)  # Wider width, auto height
        if imgui.begin_popup_modal("ErrorPopup")[0]:
            # Center title
            window_width = imgui.get_window_width()
            title_width = imgui.calc_text_size(self.error_popup_title)[0]
            imgui.set_cursor_pos_x((window_width - title_width) * 0.5)
            imgui.text(self.error_popup_title)
            imgui.separator()
            # Center message
            message_lines = self.error_popup_message.split('\n')
            for line in message_lines:
                line_width = imgui.calc_text_size(line)[0]
                imgui.set_cursor_pos_x((window_width - line_width) * 0.5)
                imgui.text(line)
            imgui.spacing()
            # Center button
            button_width = 120
            imgui.set_cursor_pos_x((window_width - button_width) * 0.5)
            if imgui.button("Close", width=button_width):
                self.error_popup_active = False
                imgui.close_current_popup()
                if self.error_popup_action_callback:
                    self.error_popup_action_callback()
            imgui.end_popup()

    def _render_all_popups(self):
        """Optimized popup rendering - only renders visible/active popups."""
        app_state = self.app.app_state_ui
        
        # Only render gauge windows if they're shown AND not in overlay mode
        if getattr(app_state, 'show_gauge_window_timeline1', False) and not self.app.app_settings.get('gauge_overlay_mode', False):
            self.gauge_window_ui_t1.render()

        if getattr(app_state, 'show_gauge_window_timeline2', False) and not self.app.app_settings.get('gauge_overlay_mode', False):
            self.gauge_window_ui_t2.render()

        # Only render Movement Bar if shown AND not in overlay mode
        if getattr(app_state, 'show_lr_dial_graph', False) and not self.app.app_settings.get('movement_bar_overlay_mode', False):
            self.movement_bar_ui.render()

        if getattr(app_state, 'show_simulator_3d', False) and not self.app.app_settings.get('simulator_3d_overlay_mode', False):
            self.simulator_3d_window_ui.render()

        # Batch confirmation dialog (has internal visibility check)
        self._render_batch_confirmation_dialog()
        
        # File dialog only if open
        if self.file_dialog.open:
            self.file_dialog.draw()
        
        # Status message (has internal visibility check)
        self._render_status_message(app_state)
        
        # Updater dialogs (have early returns to avoid expensive ImGui calls when not visible)
        self.app.updater.render_update_dialog()
        self.app.updater.render_update_error_dialog()
        self.app.updater.render_migration_warning_dialog()
        self.app.updater.render_update_settings_dialog()

        # Keyboard Shortcuts Dialog (accessible via F1 or Help menu)
        self.keyboard_shortcuts_dialog.render()

    def run(self):
        colors = self.colors
        if not self.init_glfw(): return
        target_normal_fps = self.app.energy_saver.main_loop_normal_fps_target
        target_energy_fps = self.app.energy_saver.energy_saver_fps
        if target_normal_fps <= 0: target_normal_fps = 60
        if target_energy_fps <= 0: target_energy_fps = 1
        if target_energy_fps > target_normal_fps: target_energy_fps = target_normal_fps
        target_frame_duration_normal = 1.0 / target_normal_fps
        target_frame_duration_energy_saver = 1.0 / target_energy_fps
        glfw.swap_interval(0)

        try:
            while not glfw.window_should_close(self.window):
                frame_start_time = time.time()
                
                # Track frame setup operations
                event_start = time.perf_counter()
                glfw.poll_events()
                if self.impl: self.impl.process_inputs()
                gl.glClearColor(*colors.BACKGROUND_CLEAR)
                gl.glClear(gl.GL_COLOR_BUFFER_BIT)
                event_time = (time.perf_counter() - event_start) * 1000
                self.component_render_times["FrameSetup"] = event_time
                
                # GUI rendering (internally timed)
                self.render_gui()
                if (
                    self.app.app_settings.get("autosave_enabled", True)
                    and time.time() - self.app.project_manager.last_autosave_time > self.app.app_settings.get("autosave_interval_seconds", constants.DEFAULT_AUTOSAVE_INTERVAL_SECONDS)
                ):
                    self.app.project_manager.perform_autosave()
                self.app.energy_saver.check_and_update_energy_saver()
                
                # Track buffer swap (GPU synchronization)
                swap_start = time.perf_counter()
                glfw.swap_buffers(self.window)
                swap_time = (time.perf_counter() - swap_start) * 1000
                self.component_render_times["BufferSwap"] = swap_time
                
                # Update GPU memory usage every 120 frames (~2s at 60fps) - reduced frequency  
                if self.perf_frame_count % 120 == 0:
                    gpu_start = time.perf_counter()
                    self.update_gpu_memory_usage()
                    gpu_time = (time.perf_counter() - gpu_start) * 1000
                    # Only track if it's actually expensive (>1ms)
                    if gpu_time > 1.0:
                        self.component_render_times["GPU_Monitor"] = gpu_time
                current_target_duration = target_frame_duration_energy_saver if self.app.energy_saver.energy_saver_active else target_frame_duration_normal
                elapsed_time_for_frame = time.time() - frame_start_time
                sleep_duration = current_target_duration - elapsed_time_for_frame
                
                if ( # Periodic update checks
                    self.app.app_settings.get("updater_check_on_startup", True)
                    and self.app.app_settings.get("updater_check_periodically", True)
                    and time.time() - self.app.updater.last_check_time > 3600  # 1 hour
                ):
                    self.app.updater.check_for_updates_async()
                if sleep_duration > 0:
                    time.sleep(sleep_duration)
        finally:
            self.app.shutdown_app()

            # --- Cleanly shut down all worker threads ---
            self.shutdown_event.set()
            
            # Shutdown ProcessingThreadManager first
    def _generate_instant_tooltip_data(self, hover_time_s: float, hover_frame: int, total_duration: float, normalized_pos: float, include_frame: bool = False):
        """Generate cached tooltip data with instant funscript zoom and optional delayed video frame."""
        tooltip_data = {
            'hover_time_s': hover_time_s,
            'hover_frame': hover_frame,
            'total_duration': total_duration,
            'zoom_actions': [],
            'zoom_start_s': 0,
            'zoom_end_s': 0,
            'frame_data': None,
            'frame_loading': include_frame,  # Set to True immediately if frame will be fetched
            'actual_frame': None  # Track actual frame if different from requested
        }
        
        # Funscript zoom preview (2 seconds window around hover point) - INSTANT
        zoom_window_s = 4.0  # Total window size in seconds
        zoom_start_s = max(0, hover_time_s - zoom_window_s/2)
        zoom_end_s = min(total_duration, hover_time_s + zoom_window_s/2)
        tooltip_data['zoom_start_s'] = zoom_start_s
        tooltip_data['zoom_end_s'] = zoom_end_s
        
        # Get funscript actions in zoom window - FAST operation
        actions = self.app.funscript_processor.get_actions('primary')
        if actions:
            zoom_actions = []
            for action in actions:
                action_time_s = action['at'] / 1000.0
                if zoom_start_s <= action_time_s <= zoom_end_s:
                    zoom_actions.append(action)
            tooltip_data['zoom_actions'] = zoom_actions

        # Frame extraction is handled asynchronously by the caller to avoid blocking UI
        # frame_loading is already set to True in dict initialization if include_frame is True

        return tooltip_data
    
    def _get_frame_direct_cv2(self, frame_index: int):
        """Fast direct frame extraction using video processor's existing infrastructure.
        Returns: (frame_data, actual_frame_index) or (None, None) on error
        """
        if not self.app.processor or not self.app.processor.video_path:
            return None, None

        import numpy as np

        try:
            # Use OpenCV-based thumbnail extractor for fast seeking (no FFmpeg process spawning!)
            # This is much faster than spawning FFmpeg for each tooltip hover
            # Note: This still blocks briefly for OpenCV seek, but much faster than FFmpeg
            frame = self.app.processor.get_thumbnail_frame(frame_index, use_gpu_unwarp=False)
            
            if frame is None:
                return None, None
            
            # Frame is exact, no mismatch
            actual_frame = frame_index
            # Keep frame in BGR format - update_texture will handle BGRRGB conversion
            
            # Apply VR panel selection if enabled (user override controls)
            # Note: ThumbnailExtractor already crops VR to one panel (left for SBS, top for TB)
            # This section allows user to override and select right panel for SBS content
            if hasattr(self.app, 'app_settings') and self.app.app_settings:
                vr_enabled = self.app.app_settings.get('vr_mode_enabled', False)
                vr_panel = self.app.app_settings.get('vr_panel_selection', 'full')  # 'left', 'right', 'full'

                # Only apply panel selection for SBS content (not TB)
                # TB content is already cropped to top panel by ThumbnailExtractor
                vr_format = getattr(self.app.processor, 'vr_input_format', '') if self.app.processor else ''
                is_sbs = '_sbs' in vr_format.lower() or '_lr' in vr_format.lower() or '_rl' in vr_format.lower()

                if vr_enabled and vr_panel != 'full' and is_sbs:
                    height, width = frame.shape[:2]

                    if vr_panel == 'left':
                        # Take left half for preview
                        frame = frame[:, :width//2]
                    elif vr_panel == 'right':
                        # Take right half for preview
                        frame = frame[:, width//2:]
            
            # Resize for preview (keep aspect ratio)
            height, width = frame.shape[:2]
            aspect_ratio = width / height if height > 0 else 16/9
            
            # For VR content, make preview larger since it's typically wider
            if aspect_ratio > 1.5:  # Likely VR content (wider than standard 16:9)
                preview_width = 240  # Bigger for VR
                preview_height = int(preview_width / aspect_ratio)
            else:
                preview_width = 200  # Standard content
                preview_height = int(preview_width / aspect_ratio)
            
            # Resize frame for preview
            frame_resized = cv2.resize(frame, (preview_width, preview_height), interpolation=cv2.INTER_AREA)
            
            return frame_resized, actual_frame
            
        except Exception as e:
            if hasattr(self.app, 'logger'):
                self.app.logger.debug(f"Direct cv2 frame extraction failed: {e}")
            return None, None
    
    def _render_instant_enhanced_tooltip(self, tooltip_data: dict, show_video_frame: bool = True):
        """Render enhanced tooltip using cached data."""
        imgui.begin_tooltip()
        
        try:
            # Time information header
            imgui.text(f"{_format_time(self.app, tooltip_data['hover_time_s'])} / {_format_time(self.app, tooltip_data['total_duration'])}")
            
            # Show frame number with visual indicator if video frame is available and matching
            frame_text = f"Frame: {tooltip_data['hover_frame']}"
            has_frame_data = tooltip_data.get('frame_data') is not None and tooltip_data.get('frame_data').size > 0
            actual_frame = tooltip_data.get('actual_frame', tooltip_data['hover_frame'])
            frames_match = actual_frame == tooltip_data['hover_frame']
            
            if show_video_frame and has_frame_data and frames_match:
                imgui.text_colored(frame_text, 0.0, 1.0, 0.0, 1.0)  # Green = frame and video are synchronized
            elif show_video_frame and has_frame_data and not frames_match:
                imgui.text_colored(f"{frame_text} (video: {actual_frame})", 1.0, 1.0, 0.0, 1.0)  # Yellow = mismatch warning
            else:
                imgui.text(frame_text)  # Normal color = no video preview yet
            
            imgui.separator()
            
            # Funscript zoom preview
            zoom_actions = tooltip_data.get('zoom_actions', [])
            if zoom_actions:
                # Get tooltip window width for centering
                window_width = imgui.get_window_width()
                zoom_width = min(300, window_width - 20)  # Match popup width with padding
                zoom_height = 80
                draw_list = imgui.get_window_draw_list()
                graph_pos = imgui.get_cursor_screen_pos()
                
                # Background
                draw_list.add_rect_filled(
                    graph_pos[0], graph_pos[1],
                    graph_pos[0] + zoom_width, graph_pos[1] + zoom_height,
                    imgui.get_color_u32_rgba(0.1, 0.1, 0.1, 1.0)
                )
                
                # Draw funscript curve
                zoom_start_s = tooltip_data['zoom_start_s']
                zoom_end_s = tooltip_data['zoom_end_s']
                hover_time_s = tooltip_data['hover_time_s']
                
                if len(zoom_actions) > 1:
                    for i in range(len(zoom_actions) - 1):
                        # Calculate positions
                        t1 = (zoom_actions[i]['at'] / 1000.0 - zoom_start_s) / (zoom_end_s - zoom_start_s)
                        t2 = (zoom_actions[i+1]['at'] / 1000.0 - zoom_start_s) / (zoom_end_s - zoom_start_s)
                        y1 = 1.0 - (zoom_actions[i]['pos'] / 100.0)
                        y2 = 1.0 - (zoom_actions[i+1]['pos'] / 100.0)
                        
                        x1 = graph_pos[0] + t1 * zoom_width
                        x2 = graph_pos[0] + t2 * zoom_width
                        py1 = graph_pos[1] + y1 * zoom_height
                        py2 = graph_pos[1] + y2 * zoom_height
                        
                        # Draw line segment
                        draw_list.add_line(
                            x1, py1, x2, py2,
                            imgui.get_color_u32_rgba(0.2, 0.8, 0.2, 1.0),
                            2.0
                        )
                    
                    # Draw points
                    for action in zoom_actions:
                        t = (action['at'] / 1000.0 - zoom_start_s) / (zoom_end_s - zoom_start_s)
                        y = 1.0 - (action['pos'] / 100.0)
                        x = graph_pos[0] + t * zoom_width
                        py = graph_pos[1] + y * zoom_height
                        
                        # Highlight if near hover position
                        is_near_hover = abs(action['at'] / 1000.0 - hover_time_s) < 0.1
                        color = imgui.get_color_u32_rgba(1.0, 1.0, 0.0, 1.0) if is_near_hover else imgui.get_color_u32_rgba(0.4, 1.0, 0.4, 1.0)
                        radius = 4 if is_near_hover else 3
                        
                        draw_list.add_circle_filled(x, py, radius, color)
                
                # Draw vertical line at hover position
                hover_x = graph_pos[0] + ((hover_time_s - zoom_start_s) / (zoom_end_s - zoom_start_s)) * zoom_width
                draw_list.add_line(
                    hover_x, graph_pos[1],
                    hover_x, graph_pos[1] + zoom_height,
                    imgui.get_color_u32_rgba(1.0, 0.5, 0.0, 0.8),
                    1.0
                )
                
                imgui.dummy(zoom_width, zoom_height)
            
            # Video frame preview (only show if requested after delay)
            if show_video_frame:
                imgui.separator()
                
                frame_data = tooltip_data.get('frame_data')
                frame_loading = tooltip_data.get('frame_loading', False)
                
                if frame_data is not None:
                    # Display cached frame using dedicated enhanced preview texture
                    if hasattr(self, 'enhanced_preview_texture_id') and self.enhanced_preview_texture_id:
                        # Only update texture once per cached tooltip data
                        if not hasattr(tooltip_data, '_frame_texture_updated'):
                            self.update_texture(self.enhanced_preview_texture_id, frame_data)
                            tooltip_data['_frame_texture_updated'] = True
                        
                        # Calculate dimensions to fit popup width
                        frame_height, frame_width = frame_data.shape[:2]
                        window_width = imgui.get_window_width()
                        max_width = min(300, window_width - 20)  # Match graph width
                        
                        # Scale frame to fit if needed
                        if frame_width > max_width:
                            scale = max_width / frame_width
                            display_width = max_width
                            display_height = int(frame_height * scale)
                        else:
                            display_width = frame_width
                            display_height = frame_height
                        
                        # Center the image
                        available_width = imgui.get_content_region_available()[0]
                        if display_width < available_width:
                            imgui.set_cursor_pos_x(imgui.get_cursor_pos_x() + (available_width - display_width) / 2)
                        
                        imgui.image(self.enhanced_preview_texture_id, display_width, display_height)
                        
                        # Show VR panel info only if relevant
                        if hasattr(self.app, 'app_settings') and self.app.app_settings:
                            vr_enabled = self.app.app_settings.get('vr_mode_enabled', False)
                            vr_panel = self.app.app_settings.get('vr_panel_selection', 'full')
                            if vr_enabled and vr_panel != 'full':
                                imgui.text(f"[{vr_panel.upper()} panel]")
                    else:
                        imgui.text_disabled(f"[Frame {tooltip_data['hover_frame']} - no texture available]")
                elif frame_loading:
                    imgui.text_disabled(f"[Loading...]")
                else:
                    # More helpful error message
                    if not self.app.processor:
                        imgui.text_disabled("[No video processor available]")
                    elif not self.app.processor.video_path:
                        imgui.text_disabled("[No video loaded]")
                    else:
                        imgui.text_disabled(f"[Frame extraction failed]")
            
        except Exception as e:
            imgui.text(f"Preview Error: {str(e)[:50]}")
            if hasattr(self.app, 'logger'):
                self.app.logger.error(f"Enhanced preview tooltip error: {e}")
        
        imgui.end_tooltip()

    def cleanup(self):
        try:
            # Stop native sync servers if running (managed by control panel now)
            if hasattr(self.control_panel_ui, '_native_sync_manager'):
                try:
                    self.control_panel_ui._native_sync_manager.stop()
                except Exception as e:
                    self.app.logger.error(f"Error stopping native sync: {e}")

            self.app.logger.info("Shutting down ProcessingThreadManager...")
            self.processing_thread_manager.shutdown(timeout=3.0)

            # Shutdown legacy preview worker thread
            for _ in self.preview_worker_threads:
                try:
                    self.preview_task_queue.put_nowait({'type': 'shutdown'})
                except queue.Full:
                    pass
            for t in self.preview_worker_threads:
                t.join()

            if self.frame_texture_id: gl.glDeleteTextures([self.frame_texture_id]); self.frame_texture_id = 0
            if self.heatmap_texture_id: gl.glDeleteTextures([self.heatmap_texture_id]); self.heatmap_texture_id = 0
            if self.funscript_preview_texture_id: gl.glDeleteTextures(
                [self.funscript_preview_texture_id]); self.funscript_preview_texture_id = 0

            if self.impl: self.impl.shutdown()
            if self.window: glfw.destroy_window(self.window)
            glfw.terminate()
            self.app.logger.info("GUI terminated.", extra={'status_message': False})
        except Exception as e:
            print(f"Error during cleanup: {e}")
            